[{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.5-cognito-function/5.5.1-auth-functions/","title":"Create Authentication Functions","tags":[],"description":"","content":"5.5.1 Create Authentication Functions The complete, production-ready Cognito logic ‚Äî exactly as used in your workshop\nYou are now going to create the heart of your authentication system ‚Äî a single, well-organized file containing all Cognito operations with proper error handling, TypeScript types, and role detection.\nStep 1 ‚Äì Fix Folder Name \u0026amp; Create Config (Already Done) Make sure you have:\nlib/amplify-config.ts (with ssr: true) Folder name corrected: lib/ (not libc/) Step 2 ‚Äì Create the Full Authentication Module File: lib/cognito-auth.ts\n// lib/cognito-auth.ts import { Amplify } from \u0026#39;aws-amplify\u0026#39;; import { signUp, confirmSignUp, signIn, signOut, getCurrentUser, fetchAuthSession, fetchUserAttributes, resetPassword, confirmResetPassword, type SignUpInput, } from \u0026#39;aws-amplify/auth\u0026#39;; // This import triggers Amplify configuration (side effect) import \u0026#39;@/lib/amplify-config\u0026#39;; // Optional: safety check (useful during development) function ensureAmplifyConfigured() { const config = Amplify.getConfig(); if (!config.Auth?.Cognito?.userPoolId) { console.error(\u0026#39;Amplify not configured properly. Missing userPoolId.\u0026#39;); throw new Error(\u0026#39;Auth UserPool not configured\u0026#39;); } } // ============================================ // SIGN UP // ============================================ export interface SignUpParams { email: string; password: string; name: string; } export async function cognitoSignUp({ email, password, name }: SignUpParams) { try { const { isSignUpComplete, userId, nextStep } = await signUp({ username: email.trim(), password: password.trim(), options: { userAttributes: { email: email.trim(), name: name.trim(), }, }, } as SignUpInput); return { success: true, isSignUpComplete, userId, nextStep, message: \u0026#39;Sign up successful! Check your email for verification.\u0026#39;, }; } catch (error: any) { console.error(\u0026#39;Sign up error:\u0026#39;, error); if (error.name === \u0026#39;UsernameExistsException\u0026#39;) { return { success: false, error: \u0026#39;Account already exists.\u0026#39; }; } return { success: false, error: error.message || \u0026#39;Sign up failed\u0026#39; }; } } // ============================================ // CONFIRM SIGN UP (Email Verification) // ============================================ export async function cognitoConfirmSignUp(email: string, code: string) { try { await confirmSignUp({ username: email.trim(), confirmationCode: code.trim(), }); return { success: true, message: \u0026#39;Email verified! You can now sign in.\u0026#39; }; } catch (error: any) { console.error(\u0026#39;Confirm sign up error:\u0026#39;, error); return { success: false, error: error.message || \u0026#39;Verification failed\u0026#39; }; } } // ============================================ // SIGN IN // ============================================ export interface SignInParams { email: string; password: string; } export async function cognitoSignIn({ email, password }: SignInParams) { try { const { isSignedIn, nextStep } = await signIn({ username: email.trim(), password: password.trim(), }); if (isSignedIn) { const attributes = await fetchUserAttributes(); return { success: true, isSignedIn, user: attributes, message: \u0026#39;Sign in successful!\u0026#39;, }; } return { success: false, nextStep, error: \u0026#39;Additional steps required\u0026#39; }; } catch (error: any) { console.error(\u0026#39;Sign in error:\u0026#39;, error); if (error.name === \u0026#39;NotAuthorizedException\u0026#39;) { return { success: false, error: \u0026#39;Invalid email or password\u0026#39; }; } if (error.name === \u0026#39;UserNotConfirmedException\u0026#39;) { return { success: false, error: \u0026#39;Please verify your email first\u0026#39; }; } return { success: false, error: error.message || \u0026#39;Sign in failed\u0026#39; }; } } // ============================================ // SIGN OUT // ============================================ export async function cognitoSignOut() { try { await signOut(); return { success: true, message: \u0026#39;Signed out successfully\u0026#39; }; } catch (error: any) { console.error(\u0026#39;Sign out error:\u0026#39;, error); return { success: false, error: error.message || \u0026#39;Sign out failed\u0026#39; }; } } // ============================================ // GET CURRENT USER + ROLE DETECTION // ============================================ export async function getCognitoUser() { try { // This will throw if not authenticated const currentUser = await getCurrentUser(); const attributes = await fetchUserAttributes(); const session = await fetchAuthSession(); const idTokenPayload = session.tokens?.idToken?.payload; const groups = (idTokenPayload?.[\u0026#39;cognito:groups\u0026#39;] as string[]) || []; const role = groups.includes(\u0026#39;admin\u0026#39;) ? \u0026#39;admin\u0026#39; : \u0026#39;user\u0026#39;; return { userId: currentUser.userId, username: currentUser.username, email: attributes.email || \u0026#39;\u0026#39;, name: attributes.name || \u0026#39;\u0026#39;, groups, role, }; } catch (error: any) { // Expected when user is not signed in if (error.name === \u0026#39;UserUnAuthenticatedException\u0026#39; || error.message?.includes(\u0026#39;not authenticated\u0026#39;)) { return null; } console.error(\u0026#39;Get user error:\u0026#39;, error); return null; } } // ============================================ // PASSWORD RESET (Bonus) // ============================================ export async function cognitoResetPassword(email: string) { try { await resetPassword({ username: email.trim() }); return { success: true, message: \u0026#39;Reset code sent to your email\u0026#39; }; } catch (error: any) { return { success: false, error: error.message || \u0026#39;Failed to send reset code\u0026#39; }; } } export async function cognitoConfirmResetPassword(email: string, code: string, newPassword: string) { try { await confirmResetPassword({ username: email.trim(), confirmationCode: code.trim(), newPassword, }); return { success: true, message: \u0026#39;Password reset successful!\u0026#39; }; } catch (error: any) { return { success: false, error: error.message || \u0026#39;Failed to reset password\u0026#39; }; } } Navigation:\nPrevious: 5.5 Cognito Functions Overview Next Step: 5.5.2 Build Authentication UI ‚Üí Create sign-up, sign-in, and dashboard pages "},{"uri":"https://thormastran.github.io/fcj-workshop-template/","title":"Internship Report","tags":[],"description":"","content":"Internship Report ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nStudent Information: Full Name: Tran Cong Tam\nPhone Number: 0904942288\nEmail: trancongtam613@gmail.com\nUniversity: FPT University of Technology and Education\nMajor: Information Technology\nClass: AWS082025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 09/08/2025 to 12/08/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/","title":"üìù Worklog Journey","tags":[],"description":"","content":" ‚ö†Ô∏è Important Notice: The information below serves as a reference template. Please customize and personalize this content for your own report rather than copying it directly.\nOn this page, you will need to introduce your worklog. How did you complete it? How many weeks did you take to complete the program? What did you do in those weeks?\nTypically, and as a standard, a worklog is carried out over about 3 months (throughout the internship period) with weekly contents as follows:\nWeek 1 - Foundation \u0026amp; First Steps\nGetting familiar with AWS Free Tier account, setting up IAM users with least privilege principles, exploring the Management Console and CLI, launching my first EC2 instance, creating S3 buckets for object storage, and attaching EBS volumes\nWeek 2 - Architecture \u0026amp; Networking Fundamentals Learning about AWS Well-Architected Framework, diving deep into EC2 instances, and mastering networking basics\nWeek 3 - Development \u0026amp; Security Essentials Studying Cloud9 IDE, exploring Lightsail services, and understanding monitoring \u0026amp; security basics\nWeek 4 - DNS \u0026amp; SDK Integration Implementing hybrid DNS architecture, working with AWS SDK, and configuring Amazon Route 53\nWeek 5 - Serverless \u0026amp; Database Solutions Getting started with AWS Lambda functions and implementing Amazon DynamoDB for data persistence\nWeek 6 - Security \u0026amp; Content Delivery Studying AWS Certificate Manager, advanced Route 53 configurations, and Amazon CloudFront distributions\nWeek 7 - Console Mastery \u0026amp; Serverless Architecture Understanding core AWS services, mastering console \u0026amp; CLI operations, and diving into serverless computing\nWeek 8 - Development Tools \u0026amp; AI Integration Practicing with AWS Toolkit for VS Code, exploring Amazon Q, and implementing CodeWhisperer\nWeek 9 - Advanced Networking \u0026amp; DNS Learning about VPC components, Route53 DNS endpoints, and network architecture design\nWeek 10 - Workspaces \u0026amp; Monitoring Solutions Gaining knowledge of AWS WorkSpaces, CloudFront with S3 integration, and CloudTrail implementation\nWeek 11 - Frontend Development \u0026amp; Authentication\nPracticing frontend development with Cognito AWS, Amplify framework, and Next.js applications\nWeek 12 - Knowledge Consolidation \u0026amp; Review Comprehensive review of all acquired knowledge and final project integration\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nAWS gears up for action-packed Gamescom and Devcom 2024 More than 320,000 gamers and games industry professionals are expected to gather in Cologne, Germany, next week as Gamescom gets underway. One of the world‚Äôs most anticipated games industry events, the conference brings together developers, publishers, hardware manufacturers, and cloud providers from around the world alongside the gaming community to celebrate industry achievements and discuss the trends shaping the industry‚Äôs future.\nHistorically, it‚Äôs also been a forum for launching new game development offerings, making partnership announcements, and debuting compelling technology demos. Devcom, the official game developer event of Gamescom, is an annual highlight, and Amazon Web Services (AWS) is preparing to make a splash at both events. Here‚Äôs what to expect:\nAWS on-site activities Aligning purpose-built game development services and solutions from AWS and AWS Partners against six solution areas, including Cloud Game Development, Game Servers, Live Operations, Game Security, Game Analytics, and Game Artificial Intelligence (AI) and Machine Learning (ML), AWS helps developers build, run, and grow their games. AWS is participating in a range of Devcom-related activities inside and outside the Confex Exhibitor Hall, such as:\nLive product demonstrations\nVisitors to the AWS booth (E2) can check out real-time demos of game industry‚Äìspecific AWS technology led by industry experts and partners. Among the lineup is a generative AI kiosk featuring Ada, an in-game non-player character (NPC) created with MetaHuman in Unreal Engine 5 and Amazon Bedrock, a toolset for building generative AI applications. The demo shows how this technology can make NPCs more dynamic and intelligent to enhance the player experience.\nA second demo dives deep into using Stable Diffusion within Amazon Bedrock to generate images for your mood boards, and to seamlessly integrate these generated images into Miro a popular online collaborative whiteboard platform. At the booth, AWS Partners EPAM Systems and Revolgy will also demo solutions for generative AI and cloud game development. Click the link to find out more about AWS booth demos or to schedule a meeting with an AWS industry expert at the show.\nPanels and talks\nAWS for Games leaders and partners will participate in a range of Devcom sessions, including: Monday, August 19\nA Fireside Chat on Generative AI in Gaming with Electronic Arts (EA) Head of Technology Partnerships Jeff Skelton and EPAM Systems Head of Gaming Solutions Vitalii Vashchuk from 11:30-12:00 CET on Stage 12 ‚Äì (Confex Lvl-2). Game Servers on AWS: How to Select for Success led by AWS for Games Senior Solutions Architect Benjamin Meyer and AWS for Games Solutions Architect Rieha Burrell from 15:00-15:30 CET on Stage 4 ‚Äì (Confex Lvl-1). Tuesday, August 20\nAccelerating Game Development with AWS and Revolgy featuring AWS for Games Sr. Solutions Architect Chris Blackwell and Revolgy Senior Account Manager James Turner from 11:30-12:00 CET on Stage 4 ‚Äì (Confex Lvl-1). Networking events\nThe AWS team invites attendees to unwind after a busy day on the conference floor at one of many customer and partner events, including:\nMonday, August 19\nThe fourth annual Celebrating Women in Games event, hosted by AWS, Amazon Games, and Women in Games International (WIGI) takes place on the 27th floor of K√∂lnsky from 18:00-21:00 CET and kicks off with a panel discussion led by WIGI CEO Joanie Kraut. After the panel, participants are invited to join a reception and networking event, followed by an after-party sponsored by DoIT. Space is limited, so be sure to reserve a spot. Pragma‚Äôs Backend Services House networking happy hour runs from 17:00-20:00 CET. Register on the website to see the location. Tuesday, August 20\nA Community Clubhouse learning and networking event will offer sessions from industry leaders and AWS speakers from 8:00-18:30 CET. Register here Join CleverTap Gaming and AWS for an immersive, inspiring experience with some of the brightest minds in mobile and console gaming at the Product x LiveOps Symposium, which takes place from 16:00-17:30 CET. From 19:00-22:00 CET, AccelByte, Unity, Edgegap, mod.io, Paddle, and AWS are hosting an exciting evening where developers can connect, enjoy food and drinks, and explore solutions. Register here. Wednesday, August 21\nVisit with Deconstructor of Fun, AppsFlyer, Heroic Labs, and other game development professionals for an intimate whiskey, wine, or water tasting at The Grid Bar starting at 16:00 CET. Register here.\nNew ebooks for game developers At Devcom 2024, AWS for Games is highlighting five new ebooks for game developers that touch on everything from generative AI to delivering outstanding gamer experiences. They also illustrate how to maximize the use of Amazon GameLift and game servers and reimagine game development with the cloud, as well as the anatomy of LiveOps games. See the following for more details:\nThe 2024 AWS guide to generative AI for game developers The 2024 AWS guide to generative AI for game developers is designed to help studios better understand and unlock the advantages of generative AI applications across three key areas, discover thought starters for role-relevant use cases, and much more.\nDeliver superior gaming experiences Deliver superior gaming experiences guides developers on using AWS purpose-built services and solutions to empower development teams, spur innovation, and build immersive worlds that give gamers the experiences they deserve.\nA guide to Amazon GameLift and game servers A guide to Amazon GameLift and game servers provides tips for building worlds that players don\u0026rsquo;t want to leave, even during peak hours, using an AWS server hosting option that meets your unique needs, including the use of a fully managed solution with Amazon GameLift, and more.\nReinventing game development Reinventing game development explores the transformative potential of AWS technologies for games and the workforce behind them, providing insights into the ways Sony Entertainment, Epic Games, Ubisoft, and other studios are revolutionizing their workflows with cloud-based solutions.\nGame on for LiveOps Game on for LiveOps examines the anatomy of LiveOps games, offering a closer look into how AWS products, services, and capabilities help developers build with a managed backend, understand their players, and extend player lifetime value.\nInnovative customer applications Game studios worldwide are combining advanced 3D game development technology with purpose-built global infrastructure capabilities to build, run, and grow their games. In advance of Gamescom, AWS is excited to highlight these stories, which feature:\nKinetix, a technology startup using AWS to bring generative AI tools directly to players Azur Games, a mobile game publisher and developer that migrated all its game analytics data to ClickHouse Cloud on AWS Gamer Arena, a technology startup that minimized DevOps demands and unlocked new generative AI potential leveraging AWS Omeda Studios, a game developer that swapped out the ‚ÄòPredecessor‚Äô backend in less than five months using Amazon GameLift and Pragma Singularity 6, the creators of ‚ÄòPalia‚Äô that used Amazon Elastic Kubernetes Service (Amazon EKS) and Karpenter to conquer cross-regional gaming HUDstats, an esports data and analytics company that moved from OpenAI to Amazon Bedrock to advance esports storytelling Center for Brain Health at The University of Texas at Dallas and its collaboration with AWS to grow its Charisma program using generative AI and cloud gaming Supercell, a leading mobile game company that significantly reduced downtime and provided uninterrupted player experiences using Amazon Aurora Vuvy, a gaming company that migrated its entire infrastructure to AWS in 45 days Freedom Games, a developer of a platform for the indie game community with AWS services providing the core infrastructure Omdia games industry benchmark recognition In addition to all our Gamescom activities, AWS for Games is proud to share that in July, Omdia recognized AWS as a Cloud Platforms for Games Leader in its annual Omdia Market Radar report. The report explores the cloud services market in the games industry and offers game developers and publishers insights and recommendations based on its research and analysis. AWS for Games placed highest in six out of the seven capabilities evaluated. Download and read the report.\nConclusion Gamescom is one of a few opportunities each year where the global gaming and game development community get to converge, immerse themselves in the latest gaming experiences, and interact with industry game changers. We can‚Äôt wait to see what‚Äôs in store this year!\nTo stay up to date with the latest Gamescom and Devcom developments from AWS, visit our AWS for Games Devcom webpage. Find out how game developers are transforming game workloads and experiences with AWS by signing up to meet with one of our industry experts at the show.\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nBest practices for utilizing AWS Systems Manager with AWS Fault Injection Service by David Christian, Hans Nesbitt, and Neill Reidy on 26 JUN 2025 in Advanced (300), AWS Fault Injection Service (FIS), AWS Systems Manager, Best Practices, Management Tools, Technical How-toPermalink Share\nIntroduction In today‚Äôs cloud-centric world, ensuring the resilience of mission-critical applications is paramount. The ability to withstand and recover from unexpected failures, including degradation of cloud provider services, can mean the difference between seamless operation and costly downtime. This is where the powerful combination of AWS Systems Manager (SSM) and AWS Fault Injection Service (AWS FIS) comes into play.\nFIS, launched in 2021, is a fully managed service designed to perform fault injection experiments on AWS workloads, improving reliability and resilience. While FIS provides built-in capabilities for simulating disruptive events, its integration with SSM opens a world of possibilities for creating custom, fine-grained fault injection experiments.\nIn this blog post, we‚Äôll explore best practices for using SSM with FIS. We‚Äôll delve into how this powerful duo can be leveraged to create more comprehensive and realistic chaos engineering experiments, going beyond the standard FIS actions to simulate a wider range of failure scenarios.\nThese testing techniques help ensure your critical applications‚Äîwhether they‚Äôre custom-built solutions, enterprise systems like SAP, or web applications running on IIS‚Äîremain reliable and highly available. Using SSM, you can implement comprehensive application testing that goes beyond basic infrastructure checks to verify your entire application stack is performing as expected. This approach has helped organizations prevent service disruptions and deliver consistent experiences to their end users.\nAWS Fault Injection Service (FIS) overview FIS is a managed service that enables you to perform fault injection experiments on your AWS workloads. Fault injection is based on the principles of chaos engineering. These experiments stress an application by creating disruptive events so that you can observe how your application responds. You can then use this information to improve the performance and resiliency of your applications. With FIS, you set up and run experiments that help you create the real-world conditions needed to uncover application issues.\nAmazon Systems Manager ‚Äì Run Command overview SSM helps you centrally view, manage, and operate instances at scale in AWS, on-premises, and multi-cloud environments. With the launch of a unified console experience, SSM consolidates various tools to help you complete common tasks across managed nodes (such as Amazon Elastic Compute Cloud (EC2) instances, edge devices, or on-premises servers) across AWS accounts and Regions.\nSSM‚Äôs Run Command lets you execute bash and PowerShell scripts across your entire fleet of systems‚Äîenabling everything from routine administrative tasks to complex configuration changes and even fault injection testing. This powerful capability works on any managed node, whether it‚Äôs an Amazon EC2 instance or a non-EC2 machine in your hybrid and multi-cloud environment. You can trigger these scripts through multiple interfaces, including the AWS Management Console, AWS Command Line Interface (AWS CLI), AWS Tools for PowerShell, or AWS SDKs.\nIntegration overview FIS can execute fault injection experiments through Systems Manager using two actions: aws:ssm:send-command for SSM documents directly on EC2 instances, and aws:ssm:start-automation-execution for executing automation workflows. The send-command action is ideal for direct fault injection scenarios, while start-automation-execution is better suited for complex, multi-step fault injection experiments requiring orchestration. In this blog post, we‚Äôll focus on using aws:ssm:send-command.\nFor direct command execution, AWS provides predefined fault injection documents (prefixed with AWSFIS) that handles common fault scenarios, like CPU spikes, disk consumption, memory leaks, and network packet loss. You can also create your own SSM Command documents containing custom fault injection logic that will be executed using the aws:ssm:send-command action.\nSSM Agent is Amazon software that can be installed and configured on EC2 instances, on-premises servers, or virtual machines (VMs). This makes it possible for Systems Manager to manage these resources. The agent processes requests from SSM and then runs them as specified in the request. The AWS Systems Manager Console example below shows the FIS documents.\nNote: The pre-configured SSM documents provided by FIS are supported only on EC2 instances. They are not supported on other types of managed nodes, such as on-premises servers.\nMore details on the AWSFIS documents can be found in the user guide. Figure 1: Fault Injection documents available within AWS Systems Manager\nBest practices ‚Äì Systems Manager documents This section will cover best practices for implementing SSM documents for use with FIS. We will cover structure, parameter definition, OS detection, and preconditions.\nModular structure : Break down your documents into distinct, logical steps‚Äîsimilar to how AWS-managed documents typically separate dependency installation from script execution. This modular approach allows for independent failure handling, meaning if one step fails, you can isolate and address that specific issue without impacting other components. Each step can include its own cleanup actions, making it easier to roll back changes and return systems to a known good state when problems occur. The clear separation between steps also simplifies troubleshooting by helping you quickly pinpoint where issues arise, while well-defined modules can be reused across different automation documents. \u0026#34;mainSteps\u0026#34;: [ { \u0026#34;action\u0026#34;: \u0026#34;aws:runPowerShellScript\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;ValidatePrerequisites\u0026#34;, ... }, { \u0026#34;action\u0026#34;: \u0026#34;aws:runPowerShellScript\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;StopIISAppPool\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Stop specified IIS Application Pool\u0026#34;, ... }, { \u0026#34;action\u0026#34;: \u0026#34;aws:runPowerShellScript\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;RestoreIISAppPool\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Restore IIS Application Pool to running state\u0026#34;, ... } ] Clear parameter definitions Clear parameter definitions: Parameters are defined with type, description, and often include default values and allowed patterns. Parameters are validated using allowedPattern or allowedValues to ensure correct input.\n\u0026#34;IISAppPoolName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;default\u0026#34;: \u0026#34;DefaultAppPool\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Name of the Windows IIS Application Pool to Stop\u0026#34;, \u0026#34;allowedPattern\u0026#34;: \u0026#34;^[a-zA-Z0-9]{1,50}$\u0026#34; } Leverage environment variables for dynamic configuration: Always use SSM‚Äôs built-in environment variables (like AWS_SSM_REGION_NAME) instead of hardcoding values in your scripts. This practice ensures your automation remains portable across different regions and accounts, reduces the risk of errors from manual updates, and makes your documents more maintainable. For example, rather than embedding region-specific endpoints or paths, reference AWS_SSM_REGION_NAME to automatically adapt your scripts to whatever region they‚Äôre running in. You can view variables in your session by running an AWS Run Command for the AWS-RunShellScript document and pass the appropriate command for your OS. For example, pass printenv as a command to view environment variables on Linux.\nOS detection: Implement operating system detection to enable cross-platform automation. By identifying the OS type and version before executing any commands, you can properly handle the variations across different systems. This detect-then-execute pattern allows your automation to dynamically select the appropriate package manager (such as yum for Amazon Linux/CentOS or apt for Ubuntu), locate system files correctly, and use the right command line tools for each platform. This approach ensures your automation remains reliable and consistent whether you\u0026rsquo;re managing a homogeneous environment or a diverse fleet of Linux distributions.\nDetecting Amazon Linux if [ -f \u0026#34;/etc/system-release\u0026#34; ] \u0026amp;\u0026amp; grep -i \u0026#39;Amazon Linux\u0026#39; /etc/system-release ; then if ! grep -Fiq \u0026#39;VERSION_ID=\u0026#34;2023\u0026#34;\u0026#39; /etc/os-release ; then # Amazon Linux 2 or earlier yum -y install \u0026lt;package\u0026gt; elif grep -Fiq \u0026#39;ID=\u0026#34;amzn\u0026#34;\u0026#39; /etc/os-release \u0026amp;\u0026amp; grep -Fiq \u0026#39;VERSION_ID=\u0026#34;2023\u0026#34;\u0026#39; /etc/os-release ; then # Amazon Linux 2023 yum -y install \u0026lt;package\u0026gt; else echo \u0026#34;Exiting - This SSM document supports: Amazon Linux, Ubuntu, CentOS (7, Stream 8, Stream 9)\u0026#34; exit 1 fi fi Detecting CentOS/RHEL elif grep -Fiq \u0026#39;ID=\u0026#34;centos\u0026#34;\u0026#39; /etc/os-release || grep -Fiq \u0026#39;ID=\u0026#34;rhel\u0026#34;\u0026#39; /etc/os-release ; then # Fetch OS Version os_version_number=$(grep -oP \u0026#39;(?\u0026lt;=^VERSION_ID=).+\u0026#39; /etc/os-release | tr -d \u0026#39;\u0026#34;\u0026#39;) # If the version has a decimal, this line will remove it os_major_version_number=${os_version_number%.*} # ... (EPEL repository setup) yum -y install \u0026lt;package\u0026gt; fi Preconditions: Create unified, intelligent automation by using preconditions in your SSM documents. Rather than maintaining separate Windows and Linux documents, write a single document that automatically executes the right commands for each platform. For example, your document can use ‚ÄòplatformType‚Äô preconditions to run PowerShell commands on Windows servers while executing bash scripts on Linux instances. You can also control workflow logic by using preconditions to check step completion‚Äîlike verifying dependencies are installed before proceeding to configuration steps. This is done by setting a precondition that checks if a previous step completed successfully, for example, ‚ÄòStringEquals: InstallDependencies: True‚Äô. This approach ensures that steps execute in the correct order and only when previous requirements are met, while still maintaining platform-specific intelligence. The result is more reliable automation that works across your entire infrastructure, with built-in validation between steps. - action: aws:runShellScript name: InstallDependencies precondition: StringEquals: - platformType - Linux inputs: # step inputs - action: aws:runShellScript name: ConfigureApplication precondition: StringEquals: - \u0026#39;{{ InstallDependencies }}\u0026#39; - \u0026#39;True\u0026#39; inputs: # step inputs OnFailure: Handle the flow of execution in the document by leveraging the OnFailure field. OnFailure supports two values ‚Äòexit‚Äô or ‚ÄòsuccessAndExit‚Äô. Both immediately stop processing any steps that haven‚Äôt been defined as a ‚ÄòfinallyStep‚Äô. The difference between the two is that ‚Äòexit‚Äô will return a failure status, but successAndExit will return success. Since we are running these in the context of FIS, we want the failure to also fail the experiment. OnFailure: exit is also a good pattern to add to your prerequisites to ensure the target is ready to run the experiment. Here‚Äôs what the previous example looks like with the onFailure added. - action: aws:runShellScript name: InstallDependencies precondition: StringEquals: - platformType - Linux inputs: -\tonFailure: exit # step inputs Code best practices We will now look at what can we do within the SSM FIS code to ensure best practices at all layers of the automation. For additional SSM Run Command best practices, refer use cases and best practices.\nIdempotency: Implement idempotency in your scripts to ensure reliability and prevent unintended side effects during retries or repeated executions. This means your script must thoroughly check the current state of the system before making any changes and only perform actions when necessary. For example, before installing software, verify if it‚Äôs already installed and at the correct version; before modifying configurations, confirm they aren‚Äôt already at the desired state. Design your scripts to handle interrupted executions gracefully by implementing state tracking mechanisms (such as status files or SSM Parameter Store entries) that record progress and allow subsequent runs to pick up where they left off. # Check if experiment is already running if (Test-Path -Path \u0026#39;C:\\temp\\fis_windows_iis_experiment.json\u0026#39;) { Write-Host \u0026#34;ERROR: fis_windows_iis_experiment.json already exists. Exiting.\u0026#34; Exit 1 } # Verify service exists before attempting operations if (-not (Get-IISAppPool -Name {{IISAppPoolName}} -ErrorAction SilentlyContinue)) { Write-Host \u0026#34;ERROR: Application Pool {{IISAppPoolName}} not found\u0026#34; Exit 1 } Timeouts: Set appropriate timeouts in your automation steps to enforce operational safety and enable proper error handling. Each step should include a ‚ÄòtimeoutSeconds‚Äô parameter that reflects both the expected execution time and your tolerance for delayed completion. This timeout acts as a critical safety mechanism‚Äîwhen a step exceeds its timeout, Systems Manager will terminate the execution and trigger cleanup procedures. This approach ensures your automation doesn‚Äôt leave systems in an unknown state during failures. For example, if a software installation step times out, your script should include cleanup logic to roll back any partial changes, such as removing incomplete installations or restoring original configurations. By combining timeouts with proper cleanup procedures, you maintain system integrity even when the control structure around your scripts fails or become unresponsive. Example from the AWSFIS-Run-CPU-Stress. - action: aws:runShellScript name: StopService inputs: timeoutSeconds: 60 runCommand: - | #!/bin/bash # script content here ################################# # General post fault-execution logic # ################################# DURATION={{ DurationSeconds }} if [[ -z $start_time ]];then \u0026gt;\u0026amp;2 echo \u0026#34;start_time is not defined\u0026#34; exit 1; fi elapsed_time=$(( $(date +%s) - start_time )) # Fail if the fault command exits successfully but the execution duration is less than the expected duration. # This happens when Stress-ng is killed prematurely using SIGTERM or SIGINT. if [[ \u0026#34;$elapsed_time\u0026#34; -lt \u0026#34;$DURATION\u0026#34; ]]; then \u0026gt;\u0026amp;2 echo \u0026#34;Fault took $elapsed_time seconds to execute, which is less than expected duration $DURATION\u0026#34; exit 1; fi Logging: Scripts should include echo statements to log progress and the result of the Run command SSM document. Command output can be viewed in a number of ways and is useful for debugging the document as well as recording success messages throughout the duration of the execution. Output options can be configured as part of the Run Command, logging can be viewed by navigating to the command history in SSM, or via Amazon Simple Storage Service (Amazon S3) bucket or Amazon CloudWatch logs. Note that additional configuration steps are required for setting up the S3 bucket logging and/or CloudWatch logs. Also, logging can be redirected to the local OS /tmp location which may be valuable in more complex scenarios. function Write-Log { param($Message) $timestamp = Get-Date -Format \u0026#39;yyyy-MM-dd HH:mm:ss\u0026#39; Write-Host \u0026#34;[$timestamp] $Message\u0026#34; } # Logging example Write-Log \u0026#34;Stopping IIS Application Pool: {{IISAppPoolName}}\u0026#34; # Rollback implementation try { Write-Log \u0026#34;Restoring IIS Application Pool: {{IISAppPoolName}}\u0026#34; Start-WebAppPool -Name {{IISAppPoolName}} $startedPool = Get-IISAppPool -Name {{IISAppPoolName}} if ($startedPool.State -ne \u0026#39;Started\u0026#39;) { throw \u0026#34;Failed to start application pool\u0026#34; } } catch { Write-Log \u0026#34;ERROR during restoration: $($_.Exception.Message)\u0026#34; throw } Output options can be configured in AWS Systems Manager \u0026gt; Node Tools \u0026gt; Run Command\nFigure 2: Output Options\nRun command output can be viewed after a job is run by navigating to ‚ÄúCommand history‚Äù and choosing ‚ÄúView output‚Äù\nFigure 3: ‚Äì Output from run command\nCleanup Procedures: As idempotency is a desired characteristic, we must clean up once we have completed our impairment to allow for the experiment to be re-ran. Implement cleanup procedures to remove temporary files, restore service configurations, and reset system states to their original condition. Your cleanup routines should be as thorough as your setup procedures, ensuring that each experiment truly starts from a clean slate. This includes removing any temporary files, restoring original configuration files, clearing cached data, and verifying service states. Always implement proper error handling and logging during cleanup, as failed cleanup procedures can compromise the idempotency of future experiment runs. # Windows (IIS) Cleanup Example try { Write-Log \u0026#34;Cleaning up: Deleting JSON file C:\\\\temp\\\\fis_windows_iis_experiment.json\u0026#34; Remove-Item -Path C:\\\\temp\\\\fis_windows_iis_experiment.json -Force Write-Log \u0026#34;JSON file deleted successfully\u0026#34; } catch { Write-Log \u0026#34;ERROR during cleanup: $($_.Exception.Message)\u0026#34; throw } # Linux (HTTPD) Cleanup Example echo \u0026#39;Cleaning up: Deleting /tmp/fis_linux_service_experiment.json\u0026#39; rm -f /tmp/fis_linux_service_experiment.json echo \u0026#39;JSON file deleted successfully.\u0026#39; Service State Restoration: Your FIS experiment will stress an application in testing or production environments by creating disruptive events. As chaos testing matures into production environments, it‚Äôs critical to implement checks to ensure services are properly restored. # Windows (IIS) Service Restoration try { Write-Log \u0026#34;Restoring IIS Application Pool: {{IISAppPoolName}}\u0026#34; Start-WebAppPool -Name {{IISAppPoolName}} $startedPool = Get-IISAppPool -Name {{IISAppPoolName}} if ($startedPool.State -ne \u0026#39;Started\u0026#39;) { throw \u0026#34;Failed to start application pool\u0026#34; } Write-Log \u0026#34;Application Pool restored successfully\u0026#34; } catch { Write-Log \u0026#34;ERROR during restoration: $($_.Exception.Message)\u0026#34; throw } # Linux (HTTPD) Service Restoration echo \u0026#39;Restoring service {{ServiceName}}\u0026#39; sudo systemctl start {{ServiceName}} if ! systemctl is-active --quiet {{ServiceName}}; then echo \u0026#39;ERROR: Failed to start service {{ServiceName}}\u0026#39; exit 1 fi echo \u0026#39;Service restored successfully.\u0026#39; Duration Management: Proper rollback includes managing experiment duration and ensuring timely restoration. As chaos engineering practices evolve, timing of the experiment will become more precise. Other factors may come into play as part of the experiment depending on architecture being tested; for example, dynamic scaling methods may be in place for Auto Scaling Groups. Refer planning your AWS FIS experiments for more details. # Windows Duration Management $elapsed_time = ((Get-Date) - $start_time).TotalSecondsWrite-Log \u0026#34;Elapsed time: $elapsed_time seconds\u0026#34; $remaining_time = {{DurationSeconds}} - $elapsed_time if ($remaining_time -gt 0) { Write-Log \u0026#34;Waiting for remaining time: $remaining_time seconds before restart\u0026#34; Start-Sleep -Seconds $remaining_time } # Linux Duration Management elapsed_time=$((current_time_epoch - start_time_epoch)) remaining_time=$(( {{DurationSeconds}} - elapsed_time ))if [ $remaining_time -gt 0 ]; then echo \u0026#34;Waiting for remaining time: $remaining_time seconds before restart\u0026#34; sleep $remaining_time fi Error Handling During Rollback: Implement comprehensive error handling during rollback operations. As part of the fault experiment, tests should include verbose error handling to aid in debugging and simplifying the ongoing journey of Chaos Engineering. Teams should take a continuous approach to resilience in the cloud, responding and learning based on success and failure of previous experiments. Refer to the Resilience lifecycle framework for more guidance on resilience best practices and continuous improvement. # Windows Error Handling try { # Restoration logic } catch { Write-Log \u0026#34;ERROR: Rollback failed - $($_.Exception.Message)\u0026#34; Write-Log \u0026#34;Manual intervention may be required\u0026#34; throw } finally { # Cleanup that must happen regardless of success/failure if (Test-Path -Path \u0026#39;C:\\temp\\fis_windows_iis_experiment.json\u0026#39;) { Remove-Item -Path C:\\temp\\fis_windows_iis_experiment.json -Force } } Conclusion Systems Manager and Fault Injection Service provide a powerful platform for implementing chaos engineering principles and improving the resilience of your AWS workloads. By following the best practices outlined in this blog, you can create more robust, efficient, and maintainable SSM documents for use with FIS. Key takeaways include implementing a modular structure, proper parameter management, OS detection, comprehensive error handling and logging, robust rollback mechanisms, effective timeout management, and proper signal handling. Additionally, utilizing preconditions, adhering to security best practices, and thorough testing are crucial for creating effective chaos engineering experiments.\nAs you continue to leverage SSM and FIS in your AWS environments, remember that chaos engineering is an ongoing process. Continuously refine your approach based on the insights gained from each experiment and stay updated with the latest features and best practices as noted in the AWS Resilience Lifecycle Framework. Also, for those getting started with FIS, the Chaos Engineering Workshop provides a safe environment to learn and practice experiments. By mastering the integration of Systems Manager with FIS and implementing these best practices, you‚Äôre taking a significant step towards building more resilient, fault-tolerant systems that can withstand the unpredictable nature of production environments. This not only improves your current fault injection experiments but also sets a solid foundation for future chaos engineering initiatives, ultimately leading to more reliable and robust AWS deployments.\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nEffective cost optimization strategies for Amazon Bedrock by Biswanath Mukherjee and Upendra V on 10 JUN 2025 in Amazon Bedrock, Best Practices, Cloud Cost Optimization, Generative AI, Generative AI* Permalink Comments Share\nCustomers are increasingly using generative AI to enhance efficiency, personalize experiences, and drive innovation across various industries. For instance, generative AI can be used to perform text summarization, facilitate personalized marketing strategies, create business-critical chat-based assistants, and so on. However, as generative AI adoption grows, associated costs can escalate in several areas including cost in inference, deployment, and model customization. Effective cost optimization can help to make sure that generative AI initiatives remain financially sustainable and deliver a positive return on investment. Proactive cost management makes the best of generative AI‚Äôs transformative potential available to businesses while maintaining their financial health.\nAmazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, DeepSeek, Luma, Meta, Mistral AI, Stability AI, and Amazon through a single API, along with a broad set of capabilities you need to build generative AI applications with security, privacy, and responsible AI. Using Amazon Bedrock, you can experiment with and evaluate top FMs for your use case, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources.\nWith the increasing adoption of Amazon Bedrock, optimizing costs is a must to help keep the expenses associated with deploying and running generative AI applications manageable and aligned with your organization‚Äôs budget. In this post, you‚Äôll learn about strategic cost optimization techniques while using Amazon Bedrock.\nUnderstanding Amazon Bedrock pricing Amazon Bedrock offers a comprehensive pricing model based on actual usage of FMs and related services. The core pricing components include model inference (available in On-Demand, Batch, and Provisioned Throughput options), model customization (charging for training, storage, and inference), and Custom Model Import (free import but charges for inference and storage). Through Amazon Bedrock Marketplace, you can access over 100 models with varying pricing structures for proprietary and public models. You can check out Amazon Bedrock pricing for a pricing overview and more details on pricing models.\nCost monitoring in Amazon Bedrock You can monitor the cost of your Amazon Bedrock usage using the following approaches:\nApplication inference profiles ‚Äì Amazon Bedrock provides application inference profiles that you can use to apply custom cost allocation tags to track, manage, and control on-demand FM costs and usage across different workloads and tenants. Cost allocation tagging ‚Äì You can tag all Amazon Bedrock models, aligning usage to specific organizational taxonomies such as cost centers, business units, teams, and applications for precise expense tracking. To carry out tagging operations, you need the Amazon Resource Name (ARN) of the resource on which you want to carry out a tagging operation. Integration with AWS cost tools ‚Äì Amazon Bedrock cost monitoring integrates with AWS Budgets, AWS Cost Explorer, AWS Cost and Usage Reports, and AWS Cost Anomaly Detection, enabling organizations to set tag-based budgets, receive alerts for usage thresholds, and detect unusual spending patterns Amazon CloudWatch metrics monitoring ‚Äì Organizations can use Amazon CloudWatch to monitor runtime metrics for Amazon Bedrock applications by inference profile, set alarms based on thresholds, and receive notifications for real-time management of resource usage and costs. You can monitor all parts of your Amazon Bedrock application using Amazon CloudWatch, which collects raw data and processes it into readable, near real-time metrics. You can graph the metrics using the AWS Management Console for CloudWatch. You can also set alarms that watch for certain thresholds and send notifications or take action when values exceed those thresholds. Resource-specific visibility ‚Äì CloudWatch provides metrics such as Invocations, InvocationLatency, InputTokenCount, OutputTokenCount, and various error metrics that can be filtered by model IDs and other dimensions for granular monitoring of Amazon Bedrock usage and performance. Cost optimization strategies for Amazon Bedrock When building generative AI applications with Amazon Bedrock, implementing thoughtful cost optimization strategies can significantly reduce your expenses while maintaining application performance. In this section, you‚Äôll find key approaches to consider in the following order:\nSelect the appropriate model Determine if it needs customization a. If yes, explore options in the correct order b. If no, proceed to the next step Perform prompt engineering and management Design efficient agents Select the correct consumption option This flow is shown in the following flow diagram. Choose an appropriate model for your use case Amazon Bedrock provides access to a diverse portfolio of FMs through a single API. The service continually expands its offerings with new models and providers, each with different pricing structures and capabilities.\nFor example, consider the on-demand pricing variation among Amazon Nova models in the US East (Ohio) AWS Region. This pricing is current as of May 21, 2025. Refer to the Amazon Bedrock pricing page for latest data.\nAs shown in the following table, the price varies significantly between Amazon Nova Micro, Amazon Nova Lite, and Amazon Nova Pro models. For example, Amazon Nove Micro is approximately 1.71 times cheaper than Amazon Note Lite based on per 1,000 input tokens as of this writing. If you don‚Äôt need multimodal capability and the accuracy of Amazon Nova Micro meets your use case, then you need not opt for Amazon Nova Lite. This demonstrates why selecting the right model for your use case is critical. The largest or most advanced model isn‚Äôt always necessary for every application.\nAmazon Nova models Price per 1,000 input tokens Price per 1,000 output tokens Amazon Nova Micro $0.000035 $0.00014 Amazon Nova Lite $0.00006 $0.00024 Amazon Nova Pro $0.0008 $0.0032 One of the key advantages of Amazon Bedrock is its unified API, which abstracts the complexity of working with different models. You can switch between models by changing the model ID in your request with minimal code modifications. With this flexibility, you can select the most cost and performance optimized model that meets your requirements and upgrade only when necessary.\nBest practice: Use Amazon Bedrock native features to evaluate the performance of the foundation model for your use case. Begin with an automatic model evaluation job to narrow down the scope. Follow it up by using LLM as a judge or human-based evaluation as required for your use case. Perform model customization in the right order When customizing FMs in Amazon Bedrock for contextualizing responses, choosing the strategy in correct order can significantly reduce your expenses while maximizing performance. You have four primary strategies available, each with different cost implications:\n1.Prompt Engineering ‚Äì Start by crafting high-quality prompts that effectively condition the model to generate desired responses. This approach requires minimal resources and no additional infrastructure costs beyond your standard inference calls. 2.RAG ‚Äì Amazon Bedrock Knowledge Bases is a fully managed feature with built-in session context management and source attribution that helps you implement the entire RAG workflow from ingestion to retrieval and prompt augmentation without having to build custom integrations to data sources and manage data flows. 3.Fine-tuning ‚Äì This approach involves providing labeled training data to improve model performance on specific tasks. Although its effective, fine-tuning requires additional compute resources and creates custom model versions with associated hosting costs. 4.Continued pre-training ‚Äì The most resource-intensive option involves providing unlabeled data to further train an FM on domain-specific content. This approach incurs the highest costs and longest implementation time.\nThe following graph shows the escalation of the complexity, quality, cost, and time of these four approaches. Best practice: Implement these strategies progressively. Begin with prompt engineering as your foundation‚Äîit‚Äôs cost-effective and can often deliver impressive results with minimal investment. Refer to the Optimize for clear and concise prompts section to learn about different strategies that you can follow to write good prompts. Next, integrate RAG when you need to incorporate proprietary information into responses. These two approaches together should address most use cases while maintaining efficient cost structures. Explore fine-tuning and continued pre-training only when you have specific requirements that can‚Äôt be addressed through the first two methods and your use case justifies the additional expense.\nBy following this implementation hierarchy, shown in the following figure, you can optimize both your Amazon Bedrock performance and your budget allocation. Here is the high-level mental model for choosing different options:\nUse Amazon Bedrock native model distillation feature Amazon Bedrock Model Distillation is a powerful feature that you can use to access smaller, more cost-effective models without sacrificing performance and accuracy for your specific use cases.\nEnhance accuracy of smaller (student) cost-effective models ‚Äì With Amazon Bedrock Model Distillation, you can select a teacher model whose accuracy you want to achieve for your use case and then select a student model that you want to fine-tune. Model distillation automates the process of generating responses from the teacher and using those responses to fine-tune the student model. Maximize distilled model performance with proprietary data synthesis ‚Äì Fine-tuning a smaller, cost-efficient model to achieve accuracy similar to a larger model for your specific use case is an iterative process. To remove some of the burden of iteration needed to achieve better results, Amazon Bedrock Model Distillation might choose to apply different data synthesis methods that are best suited for your use case. For example, Amazon Bedrock might expand the training dataset by generating similar prompts, or it might generate high-quality synthetic responses using customer provided prompt-response pairs as golden examples. Reduce cost by bringing your production data ‚Äì With traditional fine-tuning, you‚Äôre required to create prompts and responses. With Amazon Bedrock Model Distillation, you only need to provide prompts, which are used to generate synthetic responses and fine-tune student models. Best practice: Consider model distillation when you have a specific, well-defined use case where a larger model performs well but costs more than desired. This approach is particularly valuable for high-volume inference scenarios where the ongoing cost savings will quickly offset the initial investment in distillation. Use Amazon Bedrock intelligent prompt routing With Amazon Bedrock Intelligent Prompt Routing, you can now use a combination of FMs from the same model family to help optimize for quality and cost when invoking a model. For example, you can route between the Anthropic‚Äôs Claude model family‚Äîbetween Claude 3.5 Sonnet and Claude 3 Haiku depending on the complexity of the prompt. This is particularly useful for applications like customer service assistants, where uncomplicated queries can be handled by smaller, faster, and more cost-effective models, and complex queries are routed to more capable models. Intelligent prompt routing can reduce costs by up to 30% without compromising on accuracy.\nBest practice: Implement intelligent prompt routing for applications that handle a wide range of query complexities.\nOptimize for clear and concise prompts Optimizing prompts for clarity and conciseness in Amazon Bedrock focuses on structured, efficient communication with the model to minimize token usage and maximize response quality. Through techniques such as clear instructions, specific output formats, and precise role definitions, you can achieve better results while reducing costs associated with token consumption.\nStructured instructions ‚Äì Break down complex prompts into clear, numbered steps or bullet points. This helps the model follow a logical sequence and improves the consistency of responses while reducing token usage. Output specifications ‚Äì Explicitly define the desired format and constraints for the response. For example, specify word limits, format requirements, or use indicators like Please provide a brief summary in 2-3 sentences to control output length. Avoid redundancy ‚Äì Remove unnecessary context and repetitive instructions. Keep prompts focused on essential information and requirements because superfluous content can increase costs and potentially confuse the model. Use separators ‚Äì Employ clear delimiters (such as triple quotes, dashes, or XML-style tags) to separate different parts of the prompt to help the model to distinguish between context, instructions, and examples. Role and context precision ‚Äì Start with a clear role definition and specific context that‚Äôs relevant to the task. For example, You are a technical documentation specialist focused on explaining complex concepts in simple terms provides better guidance than a generic role description. Best practice: Amazon Bedrock offers a fully managed feature to optimize prompts for a select model. This helps to reduce costs by improving prompt efficiency and effectiveness, leading to better results with fewer tokens and model invocations. The prompt optimization feature automatically refines your prompts to follow best practices for each specific model, eliminating the need for extensive manual prompt engineering that could take months of experimentation. Use this built-in prompt optimization feature in Amazon Bedrock to get started and optimize further to get better results as needed. Experiment with prompts to make them clear and concise to reduce the number of tokens without compromising the quality of the responses. Optimize cost and performance using Amazon Bedrock prompt caching You can use prompt caching with supported models on Amazon Bedrock to reduce inference response latency and input token costs. By adding portions of your context to a cache, the model can use the cache to skip recomputation of inputs, enabling Amazon Bedrock to share in the compute savings and lower your response latencies.\nSignificant cost reduction ‚Äì Prompt caching can reduce costs by up to 90% compared to standard model inference costs, because cached tokens are charged at a reduced rate compared to non-cached input tokens. Ideal use cases ‚Äì Prompt caching is particularly valuable for applications with long and repeated contexts, such as document Q\u0026amp;A systems where users ask multiple questions about the same document or coding assistants that maintain context about code files. Improved latency ‚Äì Implementing prompt caching can decrease response latency by up to 85% for supported models by eliminating the need to reprocess previously seen content, making applications more responsive. Cache retention period ‚Äì Cached content remains available for up to 5 minutes after each access, with the timer resetting upon each successful cache hit, making it ideal for multiturn conversations about the same context. Implementation approach ‚Äì To implement prompt caching, developers identify frequently reused prompt portions, tag these sections using the cachePoint block in API calls, and monitor cache usage metrics (cacheReadInputTokenCount and cacheWriteInputTokenCount) in response metadata to optimize performance. Best practice: Prompt caching is valuable in scenarios where applications repeatedly process the same context, such as document Q\u0026amp;A systems where multiple users query the same content. The technique delivers maximum benefit when dealing with stable contexts that don‚Äôt change frequently, multiturn conversations about identical information, applications that require fast response times, high-volume services with repetitive requests, or systems where cost optimization is critical without sacrificing model performance. Cache prompts within the client application Client-side prompt caching helps reduce costs by storing frequently used prompts and responses locally within your application. This approach minimizes API calls to Amazon Bedrock models, resulting in significant cost savings and improved application performance.\nLocal storage implementation ‚Äì Implement a caching mechanism within your application to store common prompts and their corresponding responses, using techniques such as in-memory caching (Redis, Memcached) or application-level caching systems. Cache hit optimization ‚Äì Before making an API call to Amazon Bedrock, check if the prompt or similar variations exist in the local cache. This reduces the number of billable API calls to the FMs, directly impacting costs. You can check Caching Best Practices to learn more. Expiration strategy ‚Äì Implement a time-based cache expiration strategy such as Time To Live (TTL) to help make sure that cached responses remain relevant while maintaining cost benefits. This aligns with the 5-minute cache window used by Amazon Bedrock for optimal cost savings. Hybrid caching approach ‚Äì Combine client-side caching with the built-in prompt caching of Amazon Bedrock for maximum cost optimization. Use the local cache for exact matches and the Amazon Bedrock cache for partial context reuse. Cache monitoring ‚Äì Implement cache hit:miss ratio monitoring to continually optimize your caching strategy and identify opportunities for further cost reduction through cached prompt reuse. Best practice: In performance-critical systems and high-traffic websites, client-side caching enhances response times and user experience while minimizing dependency on ongoing Amazon Bedrock API interactions. Build small and focused agents that interact with each other rather than a single large monolithic agent Creating small, specialized agents that interact with each other in Amazon Bedrock can lead to significant cost savings while improving solution quality. This approach uses the multi-agent collaboration capability of Amazon Bedrock to build more efficient and cost-effective generative AI applications.\nThe multi-agent architecture advantage: You can use Amazon Bedrock multi-agent collaboration to orchestrate multiple specialized AI agents that work together to tackle complex business problems. By creating smaller, purpose-built agents instead of a single large one, you can:\nOptimize model selection based on specific tasks ‚Äì Use more economical FMs for simpler tasks and reserve premium models for complex reasoning tasks Enable parallel processing ‚Äì Multiple specialized agents can work simultaneously on different aspects of a problem, reducing overall response time Improve solution quality ‚Äì Each agent focuses on its specialty, leading to more accurate and relevant responses Best practice: Select appropriate models for each specialized agent, matching capabilities to task requirements while optimizing for cost. Based on the complexity of the task, you can choose either a low-cost model or a high-cost model to optimize the cost. Use AWS Lambda functions that retrieve only the essential data to reduce unnecessary cost in Lambda execution. Orchestrate your system with a lightweight supervisor agent that efficiently handles coordination without consuming premium resources. Choose the desired throughput depending on the usage Amazon Bedrock offers two distinct throughput options, each designed for different usage patterns and requirements:\nOn-Demand mode ‚Äì Provides a pay-as-you-go approach with no upfront commitments, making it ideal for early-stage proof of concepts (POCs) on development and test environments, applications with unpredictable or seasonal or sporadic traffic with significant variation. With On-Demand pricing, you‚Äôre charged based on actual usage:\nText generation models ‚Äì Pay per input token processed and output token generated Embedding models ‚Äì Pay per input token processed Image generation models ‚Äì Pay per image generated Provisioned Throughput mode ‚Äì By using Provisioned Throughput, you can purchase dedicated model units for specific FMs to get higher level of throughput for a model at a fixed cost. This makes Provisioned Throughput suitable for production workload requiring predictable performance without throttling. If you customized a model, you must purchase Provisioned Throughput to be able to use it. Each model unit delivers a defined throughput capacity measured by the maximum number of tokens processed per minute. Provisioned Throughput is billed hourly with commitment options of 1-month or 6-month terms, with longer commitments offering greater discounts.\nBest practice: If you‚Äôre working on a POC or on a use case that has a sporadic workload using one of the base FMs from Amazon Bedrock, use On-Demand mode to take the benefit of pay-as-you-go pricing. However, if you‚Äôre working on a steady state workload where throttling must be avoided, or if you‚Äôre using custom models, you should opt for provisioned throughput that matches your workload. Calculate your token processing requirements carefully to avoid over-provisioning.\nUse batch inference With batch mode, you can get simultaneous large-scale predictions by providing a set of prompts as a single input file and receiving responses as a single output file. The responses are processed and stored in your Amazon Simple Storage Service (Amazon S3) bucket so you can access them later. Amazon Bedrock offers select FMs from leading AI providers like Anthropic, Meta, Mistral AI, and Amazon for batch inference at a 50% lower price compared to On-Demand inference pricing. Refer to Supported AWS Regions and models for batch inference for more details. This approach is ideal for non-real-time workloads where you need to process large volumes of content efficiently.\nBest practice: Identify workloads in your application that don‚Äôt require real-time responses and migrate them to batch processing. For example, instead of generating product descriptions on-demand when users view them, pre-generate descriptions for new products in a nightly batch job and store the results. This approach can dramatically reduce your FM costs while maintaining the same output quality.\nConclusion As organizations increasingly adopt Amazon Bedrock for their generative AI applications, implementing effective cost optimization strategies becomes crucial for maintaining financial efficiency. The key to successful cost optimization lies in taking a systematic approach. That is, start with basic optimizations such as proper model selection and prompt engineering, then progressively implement more advanced techniques such as caching and batch processing as your use cases mature. Regular monitoring of costs and usage patterns, combined with continuous optimization of these strategies, will help make sure that your generative AI initiatives remain both effective and economically sustainable.Remember that cost optimization is an ongoing process that should evolve with your application‚Äôs needs and usage patterns, making it essential to regularly review and adjust your implementation of these strategies.For more information about Amazon Bedrock pricing and the cost optimization strategies discussed in this post, refer to:\nAmazon Bedrock pricing Amazon Bedrock Model Distillation Amazon Bedrock Intelligent Prompt Routing Amazon Bedrock prompt caching Process multiple prompts with batch inference Monitoring the performance of Amazon Bedrock "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.3-aws-cognito/5.3.1-create-cognito/","title":"Create a Cognito User Pool","tags":[],"description":"","content":"Create a Cognito User Pool In this section, you will create a Cognito User Pool using two methods:\nAWS Management Console (GUI) AWS CLI (Command Line Interface) Choose either method depending on your preference or environment.\n1. Create User Pool via AWS Console This is the standard method using the AWS web interface.\nStep 1 ‚Äî Open Cognito Console Go to:\nhttps://console.aws.amazon.com/cognito\nStep 2 ‚Äî Create a New User Pool Click Create user pool Under Define your application, choose\nTraditional web application Step 3 ‚Äî Configure User Pool Details User Application name: My web app - Cognito Step 4 ‚Äî Sign-in Options Select: Email (Users will log in using email addresses)\nStep 5 ‚Äî Required Attributes Required attributes:\nemail\nStep 6 ‚Äî Create User Pool Click Create user directory to fin\n2. Create User Pool via AWS CLI This option is useful if:\nYou want automation,\nYou are building IaC pipelines,\nOr you prefer command-line setup.\nStep 1 Open powershell on AWS web and Create User Pool aws cognito-idp create-user-pool \\ --pool-name \u0026#34;my-userpool\u0026#34; \\ --auto-verified-attributes email \\ --username-attributes email This command will:\nCreate a new user pool named my-userpool\nEnable email as the username\nEnable email auto-verification\nStep 2 ‚Äî Create an App Client Run:\naws cognito-idp create-user-pool-client \\ --user-pool-id \u0026lt;YOUR_USERPOOL_ID\u0026gt; \\ --client-name \u0026#34;my-app-client\u0026#34; \\ --generate-secret \\ --no-prevent-user-existence-errors \\ --allowed-o-auth-flows-user-pool-client \\ --allowed-o-auth-flows code \\ --allowed-o-auth-scopes \u0026#34;email\u0026#34; \u0026#34;openid\u0026#34; \\ --callback-urls \u0026#34;http://localhost:3000\u0026#34; \\ --logout-urls \u0026#34;http://localhost:3000\u0026#34; Replace:\n\u0026lt;YOUR_USERPOOL_ID\u0026gt;\nwith the value returned from Step 1.\nStep 3 ‚Äî Output Example A successful creation returns JSON: { \u0026#34;UserPool\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;ap-southeast-1_AbCdEf123\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;my-userpool\u0026#34; } } And:\n{ \u0026#34;UserPoolClient\u0026#34;: { \u0026#34;ClientId\u0026#34;: \u0026#34;4ab5exampleid123\u0026#34;, \u0026#34;ClientSecret\u0026#34;: \u0026#34;xyzexamplesecret\u0026#34; } } Completed\nYou now have a fully configured Cognito User Pool created via:\nAWS Console, or\nAWS CLI\nNavigation:\nPrevious: 5.3 AWS Cognito Setup Next Step: 5.3.2 Configure App Client ‚Üí Configure application client settings "},{"uri":"https://thormastran.github.io/fcj-workshop-template/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nComprehensive Summary Report: \u0026ldquo;Cloud Day Vietnam 2025\u0026rdquo; Event Overview Cloud Day Vietnam 2025 was a landmark technology conference that brought together industry leaders, government officials, technology professionals, and business executives to explore the transformative potential of cloud computing in Vietnam\u0026rsquo;s rapidly evolving digital landscape. Held as part of Amazon Web Services\u0026rsquo; continued expansion and commitment to the Southeast Asian market, this event served as a pivotal platform for discussing cloud adoption strategies, digital transformation initiatives, and the future of technology innovation in Vietnam.\nThe conference represented a significant milestone in Vietnam\u0026rsquo;s journey toward becoming a leading digital economy in the region, with particular emphasis on how cloud technologies can accelerate economic growth, enhance business competitiveness, and foster innovation across various industry sectors.\nEvent Objectives Comprehensive Introduction to Amazon Web Services Ecosystem: Provide attendees with an in-depth understanding of AWS\u0026rsquo;s extensive portfolio of cloud services, including compute, storage, database, networking, analytics, machine learning, and artificial intelligence solutions, while showcasing how these services can be leveraged to drive business transformation and innovation in the Vietnamese market.\nStrategic Partnership Development: Facilitate meaningful connections between AWS and local Vietnamese businesses, government agencies, and technology partners to establish long-term collaborative relationships that support digital transformation initiatives across multiple industry verticals.\nFinancial Services Digital Transformation: Explore the revolutionary impact of cloud computing on the financial services sector, demonstrating how AWS solutions can help banks, fintech companies, and financial institutions dissolve traditional boundaries between business operations and IT infrastructure, enabling greater agility, security, and customer-centric innovation.\nKnowledge Transfer and Skill Development: Provide comprehensive training opportunities and hands-on learning experiences to help Vietnamese technology professionals, developers, and business leaders acquire the skills necessary to successfully implement and manage cloud-based solutions in their organizations.\nDistinguished Keynote Speakers and Industry Leaders H.E. Pham Duc Long ‚Äì Deputy Minister of Science and Technology of Vietnam: A visionary leader in Vietnam\u0026rsquo;s science and technology sector, H.E. Pham Duc Long has been instrumental in shaping the country\u0026rsquo;s digital transformation strategy and promoting innovation-driven economic development. His keynote address focused on the Vietnamese government\u0026rsquo;s commitment to fostering a robust digital economy and the strategic importance of cloud computing technologies in achieving national development goals. He discussed policy initiatives, regulatory frameworks, and government support programs designed to accelerate technology adoption across public and private sectors.\nH.E. Marc E. Knapper ‚Äì U.S. Ambassador to the Socialist Republic of Vietnam: Ambassador Knapper brought a diplomatic and international perspective to the conference, highlighting the growing technology partnership between the United States and Vietnam. His presentation emphasized the role of American technology companies like Amazon in supporting Vietnam\u0026rsquo;s digital transformation journey while fostering bilateral economic cooperation and technological exchange. He discussed trade relationships, investment opportunities, and the mutual benefits of strengthening technological collaboration between the two nations.\nDr. Jen Lottner ‚Äì Chief Executive Officer, Techcombank: As the leader of one of Vietnam\u0026rsquo;s most innovative digital banks, Dr. Lottner shared compelling insights into how cloud technologies have revolutionized the financial services industry. Her presentation showcased Techcombank\u0026rsquo;s successful digital transformation journey, including the implementation of cloud-native architectures, artificial intelligence-powered customer services, and data-driven decision-making processes. She discussed the challenges and opportunities facing traditional financial institutions in their transition to digital-first business models.\nDieter Botha ‚Äì Chief Executive Officer, Tymex: A prominent figure in Vietnam\u0026rsquo;s fintech landscape, Dieter Botha presented innovative approaches to financial technology solutions and digital payment systems. His session focused on how cloud computing enables fintech startups to scale rapidly, implement sophisticated security measures, and deliver seamless customer experiences. He shared insights into regulatory compliance, risk management, and the future of digital financial services in emerging markets.\nUy Tran ‚Äì Co-Founder \u0026amp; Chief Operating Officer, Katalon: Representing Vietnam\u0026rsquo;s growing software development and testing industry, Uy Tran demonstrated how cloud technologies enable software companies to build, test, and deploy applications at scale. His presentation highlighted Katalon\u0026rsquo;s journey from a local startup to an internationally recognized software testing platform, emphasizing the role of cloud infrastructure in supporting global expansion and innovation.\nAWS Generative AI GameDay: Immersive Learning Experience The AWS Generative AI GameDay represented one of the conference\u0026rsquo;s most engaging and technically sophisticated components, designed to provide participants with hands-on experience in artificial intelligence and machine learning technologies. This carefully structured, gamified learning environment challenged attendees to solve complex, real-world business problems using Amazon\u0026rsquo;s cutting-edge AI services, particularly focusing on Amazon Bedrock and its comprehensive suite of foundation models.\nParticipants were organized into cross-functional teams comprising developers, data scientists, business analysts, and technical architects, creating a collaborative environment that mirrors real-world project scenarios. Each team received access to a fully configured AWS sandbox environment, complete with pre-loaded datasets, development tools, and comprehensive documentation to support their learning journey.\nThe GameDay scenarios were carefully crafted to represent authentic business challenges across multiple industry verticals, including:\nCustomer Service Automation: Teams built intelligent chatbots and virtual assistants using Amazon Bedrock\u0026rsquo;s Claude and Titan models to handle customer inquiries, process support requests, and provide personalized recommendations.\nContent Generation and Optimization: Participants developed solutions for automated content creation, including marketing copy generation, technical documentation writing, and multilingual content translation using various foundation models.\nData Analysis and Insights: Teams implemented AI-powered analytics solutions that could process large datasets, generate business insights, and create executive summaries using natural language processing capabilities.\nComprehensive Learning Outcomes: Deep Technical Proficiency with Amazon Bedrock: Participants gained extensive hands-on experience with Amazon\u0026rsquo;s fully managed service for building and scaling generative AI applications, including model selection, prompt engineering, and fine-tuning techniques.\nAdvanced Generative AI Implementation Skills: Attendees developed practical expertise in designing, implementing, and optimizing generative AI solutions for real business use cases, including understanding model limitations, performance optimization, and cost management strategies.\nCollaborative Problem-Solving Methodologies: Through team-based challenges, participants enhanced their ability to work effectively in diverse, cross-functional groups while tackling complex technical problems under time constraints.\nStrategic Foundation Model Selection: Participants learned to evaluate and select appropriate foundation models based on specific use case requirements, performance characteristics, cost considerations, and ethical AI principles.\nProduction-Ready Development Practices: The experience included best practices for developing, testing, and deploying AI applications in production environments, including security considerations, monitoring, and scalability planning.\nSkills Builders Zone: Comprehensive Professional Development Hub The Skills Builders Zone served as the conference\u0026rsquo;s premier professional development destination, featuring a meticulously designed learning environment that catered to technology professionals at every stage of their cloud computing journey. This expansive area was staffed by AWS-certified training specialists, solutions architects, and technical evangelists who provided personalized guidance and mentorship throughout the event.\nThe zone was strategically organized into multiple learning tracks, each focusing on specific technology domains and career progression paths. Participants could engage with cutting-edge AWS services through guided demonstrations, participate in instructor-led workshops, and access self-paced learning modules designed to accommodate different learning styles and time constraints.\nDetailed Learning Opportunities and Resources: Foundational Cloud Computing Track: Designed for professionals new to cloud technologies, this comprehensive learning path covered essential concepts including cloud architecture principles, service models (IaaS, PaaS, SaaS), deployment strategies, and cost optimization fundamentals. Participants gained practical experience with core AWS services including Amazon EC2, Amazon S3, Amazon VPC, and AWS IAM through guided hands-on exercises.\nAdvanced Technical Specializations: Experienced professionals could dive deep into specialized domains including:\nMachine Learning and Artificial Intelligence: Comprehensive workshops on Amazon SageMaker, AWS DeepLens, Amazon Rekognition, and Amazon Comprehend, with practical exercises in model training, deployment, and optimization. Security and Compliance: Advanced sessions covering AWS security best practices, encryption strategies, compliance frameworks, and identity management solutions including AWS Security Hub, AWS Config, and AWS CloudTrail. Infrastructure Automation and DevOps: Intensive training on AWS CloudFormation, AWS CDK, AWS CodePipeline, and container orchestration using Amazon EKS and AWS Fargate. Professional Certification Preparation: The zone provided comprehensive resources for AWS certification preparation, including:\nDetailed examination blueprints and study guides for all AWS certification levels Practice examinations with detailed explanations and performance analytics One-on-one consultation sessions with AWS training specialists to develop personalized study plans Access to AWS Training and Certification digital learning resources and practice labs Interactive Technical Laboratories: State-of-the-art hands-on learning environments where participants could:\nBuild and deploy real applications using AWS services in guided scenarios Experiment with emerging technologies including serverless computing, edge computing, and IoT solutions Participate in troubleshooting exercises and performance optimization challenges Collaborate on team-based projects that simulate real-world development scenarios Career Development and Industry Insights: Professional development sessions featuring:\nPanel discussions with AWS partners and customers sharing career progression strategies Networking opportunities with hiring managers from leading technology companies Resume review sessions and interview preparation workshops Industry trend analysis and future skill requirement forecasting Comprehensive Key Takeaways and Strategic Insights from Cloud Day Vietnam 2025 Participating in Cloud Day Vietnam 2025 provided transformative insights into the current state and future direction of cloud computing in Southeast Asia, with particular focus on Vietnam\u0026rsquo;s rapidly evolving technology landscape. The event served as a catalyst for understanding how global technology trends intersect with local market dynamics and business requirements.\nStrategic Business and Technology Insights: Government Digital Transformation Initiative: The conference highlighted Vietnam\u0026rsquo;s comprehensive national digital transformation strategy, with government officials outlining ambitious plans to modernize public services, improve citizen engagement, and foster innovation-driven economic growth. Key initiatives include the development of smart city infrastructure, digital government services, and comprehensive cybersecurity frameworks that leverage cloud technologies to enhance efficiency and security.\nFinancial Services Revolution: The event provided deep insights into how cloud computing is fundamentally reshaping Vietnam\u0026rsquo;s financial services sector. Leading institutions demonstrated how they\u0026rsquo;re leveraging AWS services to implement real-time payment systems, advanced fraud detection mechanisms, and personalized customer experiences. The transformation extends beyond traditional banking to include innovative fintech solutions, digital lending platforms, and blockchain-based financial products.\nEnterprise Cloud Adoption Patterns: Comprehensive case studies revealed how Vietnamese enterprises across manufacturing, retail, healthcare, and education sectors are implementing cloud-first strategies to improve operational efficiency, reduce infrastructure costs, and accelerate time-to-market for new products and services. The presentations highlighted both successes and challenges in cloud migration, providing valuable lessons for organizations at various stages of their digital transformation journey.\nProfessional Development and Skill Acquisition: Advanced Technical Competencies: The hands-on workshops and GameDay experiences provided practical expertise in cutting-edge technologies including artificial intelligence, machine learning, serverless computing, and container orchestration. Participants gained proficiency in using AWS services like Amazon Bedrock, Amazon SageMaker, AWS Lambda, and Amazon EKS through real-world project scenarios.\nIndustry Best Practices and Methodologies: The event showcased proven approaches to cloud architecture design, security implementation, cost optimization, and performance monitoring. Participants learned about industry standards for DevOps practices, continuous integration/continuous deployment (CI/CD) pipelines, and infrastructure as code methodologies.\nCross-Cultural Technology Collaboration: The international nature of the event provided valuable insights into how global technology companies adapt their solutions and strategies for local markets, highlighting the importance of cultural sensitivity, regulatory compliance, and local partnership development in successful technology implementations.\nNetworking and Professional Relationships: Strategic Professional Connections: The event facilitated meaningful connections with C-level executives, government officials, technology leaders, and international business partners. These relationships provide ongoing opportunities for collaboration, knowledge sharing, and potential business partnerships that extend far beyond the conference itself.\nMentorship and Career Guidance: Interactions with senior AWS professionals, solutions architects, and industry veterans provided invaluable career guidance, including insights into skill development priorities, certification pathways, and emerging career opportunities in cloud computing and related fields.\nCommunity Building and Knowledge Sharing: The event fostered the development of a vibrant professional community focused on cloud computing excellence in Vietnam, with ongoing collaboration opportunities through user groups, technical forums, and future educational events.\nFuture Technology Trends and Market Opportunities: Emerging Technology Integration: The conference provided forward-looking insights into how artificial intelligence, machine learning, Internet of Things (IoT), and edge computing will converge to create new business opportunities and transform existing industry paradigms. Particular attention was given to how these technologies can address specific challenges in the Vietnamese market.\nSustainability and Green Technology: Discussions highlighted the growing importance of sustainable technology practices, including energy-efficient cloud computing, carbon footprint reduction strategies, and how cloud adoption can support environmental sustainability goals while reducing operational costs.\nRegional Market Expansion: The event provided strategic insights into how Vietnamese companies can leverage cloud technologies to expand into regional and global markets, including discussions of regulatory considerations, cultural adaptation strategies, and technology infrastructure requirements for international expansion.\nLong-term Impact and Continued Learning: Ongoing Professional Development: The event established a foundation for continued learning through access to AWS training resources, certification programs, and ongoing professional development opportunities. Participants received roadmaps for skill development that align with industry trends and career advancement goals.\nInnovation Catalyst: The knowledge and connections gained at the event serve as catalysts for innovation within participants\u0026rsquo; organizations, providing the technical expertise and strategic insights necessary to drive meaningful digital transformation initiatives.\nIndustry Leadership Preparation: The comprehensive exposure to cutting-edge technologies, best practices, and strategic thinking prepares participants to assume leadership roles in their organizations\u0026rsquo; digital transformation efforts and contribute to Vietnam\u0026rsquo;s growing reputation as a regional technology hub.\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.4-next.js-setup/5.4.1-install-nextjs/","title":"Install Next.js Project","tags":[],"description":"","content":"Prepare the Environment In this step, you will create a new Next.js project and install required UI libraries that will be used later in the authentication interface.\n1. Create a New Next.js Project If you are starting from scratch, run the following command:\nnpx create-next-app@latest my-cognito-app When prompted: Ok to proceed? (y)\nChoose y, then navigate into the project directory:\ncd my-cognito-app 2. Install shadcn/ui (UI Component Library) You will use shadcn/ui to build the authentication UI later.\nInitialize shadcn:\nnpx shadcn@latest init This will set up the component generator for your project.\nYour environment is now ready for the next steps, where you will install Amplify SDK and configure the AWS Cognito integration.\nNavigation:\nPrevious: 5.4 Next.js Project Setup Next Step: 5.4.2 Install Amplify SDK ‚Üí Install and configure Amplify SDK "},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 1 Objectives: Connect and get acquainted with First Cloud Journey members. Understand basic AWS services, how to use Console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations , listening - Know some new information about AWS 09/06/2025 09/06/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database - Learn about module 1 09/09/2025 09/09/2025 https://www.youtube.com/watch?v=HxYZAK1coOI\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=4 4 - AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI\n-Create Usage Budget,VCP,EC2,user 09/10/2025 09/10/2025 https://aws.amazon.com/vi/free/free-tier-faqs/#topic-0 5 - AWS Identity and Access Management (IAM)\n- Types of cloud computing\n- The AWS command Line Interface (CLI), the AWS Software Development Kits (SDKs), AWS software development kits (SDKS). 09/11/2025 09/11/2025 https://aws.amazon.com/vi/iam/\nhttps://www.geeksforgeeks.org/cloud-computing/types-of-cloud/ 6 - S3(simple storage service) - EBS(Elastic Block Storage)\n- EFS(Elastic File Storage )\n-Benefits of S3 Static Website Hosting + Attach an EBS volume 09/11/2025 09/11/2025 https://www.geeksforgeeks.org/techtips/difference-between-aws-s3-and-aws-ebs/ Week 1 Achievements: Gained foundational knowledge of core AWS services, including Compute (EC2), Storage (S3), Networking (VPC), and Databases (RDS). Successfully created and secured an AWS Free Tier account for learning and practice purposes. Mastered navigation and resource management through both AWS Management Console and AWS Command Line Interface (CLI). Configured AWS CLI with secure credentials and default settings for automation and efficient service management. Performed basic operations via CLI, including: account configuration, region listing, EC2 key pair management, and service status checks. Developed foundational skills in AWS services (Compute, Storage, Networking, Database). Proficient in using both Console and CLI to deploy, configure, and manage cloud resources effectively. "},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 2 Objectives: AWS architectures. Practice with EC2. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Practice explaining AWS architectures and services to non-technical stakeholders.\n- Overview of Amazon RDS as a managed service for running relational databases. 09/08/2025 09/08/2025 https://www.datacamp.com/blog/learn-aws 3 - Definition of a DB instance (the compute and storage resources you allocate).\n- Introduction to AWS Cloud9, a browser-based integrated development environment. 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Introduction to AWS networking and content delivery.\n- Review of the AWS Management Console and AWS CLI.\n- Hands-on: create an AWS account, install and configure the AWS CLI, and practice basic CLI commands. 09/10/2025 09/10/2025 https://000092.awsstudygroup.com/ 5 - EC2 basics: instance types, AMIs, EBS volumes, and related concepts.\n- Methods for connecting to EC2 via SSH.\n- Overview of Elastic IP addresses. 09/11/2025 09/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practical lab: launch an EC2 instance, connect over SSH, and attach an EBS volume. 09/12/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ Week 2 Achievements: Gained a solid introduction to AWS and its primary service categories (Compute, Storage, Networking, Database, etc.). Created and configured an AWS Free Tier account. Learned to navigate the AWS Management Console and locate/use services through the web UI. Installed and configured the AWS CLI, including credentials (Access Key, Secret Key) and default region. Performed basic CLI tasks such as checking account/configuration details, listing regions, inspecting EC2, creating and managing key pairs, and querying running resources. Developed the ability to manage AWS resources both from the console and via the CLI. Continued hands-on practice to reinforce these skills. "},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 3 Objectives: Get started with AWS cloud 9. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Review week 2 - Monitor with Amazon Cloudwatch 09/14/2025 09/14/2025 3 - Get started with AWS cloud 9 09/15/2025 09/15/2025 https://000049.awsstudygroup.com 4 - Using command line - Working with text files - Back to Dashboard interface\n- Using AWS CLI 09/16/2025 09/16/2025 https://000049.awsstudygroup.com/4-cleanup/ 5 - AMAZON LIGHTSAIL WORKSHOP and COST OPTIMIZATION ON AWS + Deploy a Database on Lightsail\n+ Deploying a wordpress istance + Deploying prestashop e-commerce instance + Deploying an AKAUNTING instance\n09/17/2025 09/17/2025 https://000045.awsstudygroup.com/1-database/ 6 - Practice: Application security + create snapshot + create a alarm 09/18/2025 09/18/2025 https://000045.awsstudygroup.com/5-secure-the-applications/ Week 3 Achievements: Reviewed prior material and set up monitoring with Amazon CloudWatch. Launched and explored AWS Cloud9 to develop and edit directly in the cloud. Practiced CLI workflows: editing text files, navigating the Dashboard, and using AWS CLI commands. Completed Lightsail workshop: deployed database, WordPress, PrestaShop, and Akaunting instances; reviewed cost optimization strategies. Implemented basic application security tasks: created snapshots and configured alarms to monitor resources. "},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 4 Objectives: Set up hybrid DNS with route 53 resolver. Work with Amazon dynamodb. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Set up hybrid DNS with route 53 resolver - Route 53 offers various DNS capabilities, including: + Public DNS domain registration + Creation of private DNS zones + DNS hybrid engine + Domain name resolution 09/22/2025 09/22/2025 https://000010.awsstudygroup.com/1-introduce/ 3 - AWS Quick Starts - AWS CloudFormation - Storage - AWS Directory Service 09/23/2025 09/23/2025 https://000010.awsstudygroup.com/3-connecttordgw/ 4 - Set up DNS - Practice: + Create Route 53 Outbound Endpoint + Create Route 53 Resolver Rules + Create Route 53 Inbound Endpoints 09/24/2025 09/24/2025 https://000010.awsstudygroup.com/5-setuphyriddns/ 5 - Work with Amazon DynamoDB - Manage using AWS - Begin with AWS SDK 09/25/2025 09/25/2025 https://000060.awsstudygroup.com/3-gettingstartedwithawssdk// 6 - AMAZON ELASTICACHE - REDIS 09/26/2025 09/26/2025 https://000061.awsstudygroup.com Week 4 Achievements: Hybrid DNS concepts with Amazon Route¬†53 Resolver: outbound/inbound endpoints, resolver rules, and private hosted zones. Route¬†53 capabilities: public domain registration, private zones, and DNS resolution patterns. DynamoDB fundamentals: data model, capacity modes, basic CRUD patterns. AWS tooling and patterns: AWS Management Console, CLI configuration, AWS SDK usage, CloudFormation, Quick Starts, and AWS Directory Service. ElastiCache (Redis) basics and common use cases. "},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 5 Objectives: Getting started with AWS lambda functions Amazon DynamoDB for data persistence Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - AWS offers a comprehensive suite of serverless services, including:\n+ Compute: AWS Lambda\n+ Databases: Amazon Aurora Serverless v2, Amazon DynamoDB, Amazon Redshift Serverless\n+ Analytics: Amazon Athena, Amazon Kinesis Data Analytics\n+ Application Integration: Amazon EventBridge, Amazon SQS, Amazon SNS 09/29/2025 09/29/2025 https://000078.awsstudygroup.com/1-introduce/ 3 - Implement serverless image resizing using AWS Lambda 09/30/2025 09/30/2025 https://cloudjourney.awsstudygroup.com/ 4 - Writing Data to Amazon DynamoDB + An AWS account with appropriate permissions\n+ Basic understanding of Python programming\n+ Familiarity with AWS Lambda concepts\n+ Basic knowledge of NoSQL databases 10/01/2025 10/01/2025 https://000078.awsstudygroup.com/3-write-data-to-dynaomodb/ 5 - Authentication with Amazon Cognito + Create User Pool\n+ Create API and Lambda a 10/02/2025 10/02/2025 https://000081.awsstudygroup.com/1-preparation/ 6 - Using AWS IAM Identity Center for Robust Identity Management 10/03/2025 10/0//2025 https://000012.awsstudygroup.com/ Week 5 Achievements: Explored AWS\u0026rsquo;s comprehensive suite of serverless services, including:\nCompute: AWS Lambda\nDatabases: Amazon Aurora Serverless v2, Amazon DynamoDB, Amazon Redshift Serverless\nAnalytics: Amazon Athena, Amazon Kinesis Data Analytics\nApplication Integration: Amazon EventBridge, Amazon SQS, Amazon SNS\nImplemented a serverless image resizing solution using AWS Lambda.\nLearned how to write data to Amazon DynamoDB, gaining hands-on experience with:\nAWS account permissions Python programming basics AWS Lambda concepts NoSQL database fundamentals Practiced authentication with Amazon Cognito by:\nCreating a User Pool\nSetting up an API and Lambda function\nEnhanced understanding of identity management by using AWS IAM Identity Center for robust identity and access control.\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 6 Objectives: Serverless - Setting up SSL for your serverless app AWS Certificate Manager,Amazon Route 53,Amazon CloudFront Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Create Domain , Hosted zone and Request SSL certificate 10/06/2025 10/06/2025 https://000082.awsstudygroup.com/2-create-domain-hosted-zone/ 3 - Create CloudFront distribution and clean up 10/07/2025 10/07/2025 https://000082.awsstudygroup.com/4-create-cloud-front/ 4 - Serverless - Processing orders with SQS and SNS 10/08/2025 10/08/2025 https://000083.awsstudygroup.com/ 5 - Create API and Lambda functionCreate API and Lambda function\n- Practice: +Create OrdersTable DynamoDB table\n+Create checkout_order Lambda function\n+Create order_management Lambda function\n+Create handle_order Lambda function\n10/09/2025 10/09/2025 https://000083.awsstudygroup.com/3-create-api-lambda-function/ 6 - Test web operation and Clean up 10/10/2025 10/10/2025 https://000083.awsstudygroup.com/4-test-operation/ Week 6 Achievements: Created domain and hosted zone, requested and validated an SSL/TLS certificate using AWS Certificate Manager. Provisioned an Amazon CloudFront distribution and performed cleanup steps to reduce cost/resources. Implemented serverless order-processing patterns using Amazon SQS and Amazon SNS for decoupled messaging and event notification. Built and deployed REST API endpoints backed by AWS Lambda functions: Created an OrdersTable in Amazon DynamoDB for order persistence. Implemented Lambda functions for checkout (checkout_order), order management (order_management), and order handling (handle_order). Tested end-to-end web operations and performed cleanup of temporary/test resources. "},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 7 Objectives: Serverless - CI/CD with AWS CodePipeline Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Build SAM pipeline - Create Git repository\n- Create SAM pipeline 10/13/2025 10/13/2025 https://000084.awsstudygroup.com/2-build-sam-pipeline/ 3 - Build pipeline for front-end 10/14/2025 10/14/2025 https://000084.awsstudygroup.com/3-build-frontend-pipeline/ 4 - Serverless - introduction to AWS APPSYNC 10/15/2025 10/15/2025 https://000086.awsstudygroup.com/2-tutorial-dynamodb-resolvers/ 5 - DYNAMODB resolvers - Practice: + Preparation + Writing data + Reading data + Updating data + Deleting data + Scanning table + Querying table 10/16/2025 10/16/2025 https://000086.awsstudygroup.com/2-tutorial-dynamodb-resolvers/ 6 - Create complex object - Clean up 10/17/2025 10/17/2025 https://000086.awsstudygroup.com/4-clean-up/ Week 7 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 8 Objectives: AWS TOOLKIT FOR VS CODE: AMAZON Q \u0026amp; CODEWHISPERER AWS NETWORKING AND CONTENT DELIVERY Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with The Power of Amazon CodeWhisperer - Read and take note of internship unit rules and regulations 10/20/2025 10/20/2025 3 - AUTOMATICALLY ARCHIVE AMAZON EBS SNAPSHOTS WITH AMAZON DATA LIFECYCLE MANAGER 10/21/2025 10/21/2025 https://000088.awsstudygroup.com/3-connecting-to-aws/ 4 - Amazon Macie - We will create the S3 bucket and activate the Macie. - Practice: + Create S3 bucket + Enable Macie 10/22/2025 10/22/2025 https://000090.awsstudygroup.com/1-introduce/ 5 - MACIE JOB RUN AND FINDINGS + CREATE CUSTOM DATA IDENTIFIERS 10/23/2025 10/23/2025 https://000090.awsstudygroup.com/3-macie/ 6 - AWS NETWORKING AND CONTENT DELIVERY 10/24/2025 10/24/2025 https://000092.awsstudygroup.com Week 8 Achievements: Explored AWS Toolkit for VS Code and Amazon CodeWhisperer:\nInstalled and tested CodeWhisperer code suggestions inside VS Code. Validated sample completions and learned how to accept, modify, and apply suggestions to speed up development. Automated EBS snapshot lifecycle management with Amazon Data Lifecycle Manager:\nCreated and applied a lifecycle policy to automatically archive EBS snapshots. Verified snapshot creation and retention settings in the console. Implemented Amazon Macie for S3 data discovery and protection:\nCreated an S3 bucket and enabled Macie for the bucket. Ran Macie job(s) and reviewed findings; created custom data identifiers to reduce false positives. "},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 9 Objectives: VPC Components Deep Dive AWS Networking and Content Delivery Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Transit Gateway and Site-to-Site - Datacenter Router and Transit Gateway Deployment VPNs 11/03/2025 11/03/2025 https://000092.awsstudygroup.com/4-transitgatewayandvpn/ 3 - Route53 DNS Endpoints and Internal Hosted Zones + DNS Components Deployment + DNS Testing 11/04/2025 11/04/2025 https://000092.awsstudygroup.com/5-route53/5.2-dnstesting/ 4 - VPC Endpoints for AWS Services - Practice: + VPC Endpoints - Deployment + NP2 Endpoint Testing + VPC Endpoint Services 11/05/2025 11/05/2025 https://000092.awsstudygroup.com/7-vpcendpointonpremise/ 5 - VPC Endpoint Services - Deployment 11/06/2025 11/06/2025 https://000092.awsstudygroup.com/7-vpcendpointonpremise/7.1-vpcendpointservicesdeployment/ 6 - VPC Peering - Practice: + VPC Peering Request\n+ Routing Configuration + Final Testing 11/07/2025 11/07/2025 https://000092.awsstudygroup.com/8-vpcpeering/8.2-routeconf/ Week 9 Achievements: Mastered AWS Transit Gateway and Site-to-Site VPN connectivity:\nDeployed and configured Transit Gateway for multi-VPC connectivity. Set up Site-to-Site VPN connections between datacenter router and AWS. Configured routing tables and tested connectivity across hybrid network architecture. Implemented Route53 DNS solutions for internal networking:\nDeployed DNS components including Route53 resolver endpoints. Created and configured internal hosted zones for private domain resolution. Conducted comprehensive DNS testing to validate resolution across VPCs and on-premises. Configured VPC Endpoints for secure AWS service access:\nDeployed VPC endpoints to access AWS services without internet gateway. Tested endpoint connectivity and validated secure communication paths. Implemented VPC endpoint services for custom application access. "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.1-workshop-overview/","title":"Workshop Overview","tags":[],"description":"","content":"5.1 Workshop Overview What are Amazon Cognito and AWS Amplify? ‚Ä¢ Why use them together?\nWhat is Amazon Cognito? Amazon Cognito is AWS‚Äôs fully managed identity service that provides:\nUser sign-up \u0026amp; sign-in (email/password, social logins, SAML/OIDC) Built-in email/phone verification Multi-factor authentication (MFA) User directory with custom attributes and groups Secure JWT tokens (ID token, access token, refresh token) Scales automatically to millions of users Free tier: 50,000 monthly active users In this workshop, we use Cognito User Pools as our secure backend identity provider.\nWhat is AWS Amplify (Gen 2 / v6+)? AWS Amplify is the official AWS toolkit for frontend and mobile developers.\nThe new Amplify Gen 2 library (v6+) released in 2024‚Äì2025 is completely rewritten and is now:\nTree-shakable (only import what you use) Fully SSR-compatible (ssr: true) Designed specifically for Next.js App Router \u0026amp; React Server Components No more @aws-amplify/ui-react or Hosted UI required Uses the new modular @aws-amplify/auth, @aws-amplify/datastore, etc. We will use only the Auth category of Amplify Gen 2 ‚Äî the cleanest, most secure, and most modern way to connect a Next.js app to Cognito.\nWhy Use Cognito + Amplify Gen 2 Together in 2025? Benefit Explanation Rapid \u0026amp; Secure Development Amplify abstracts all token handling, refresh logic, and Cognito API calls SSR \u0026amp; App Router Ready Works perfectly with ssr: true ‚Üí no hydration errors, no window is not defined No Client Secret Public SPA client (no secret needed) ‚Üí safe for Next.js \u0026amp; Vercel Production-Grade Security Tokens never touch localStorage on server, automatic refresh, secure by default Role-Based Access Uses Cognito Groups ‚Üí cognito:groups in ID token ‚Üí easy admin/user detection Deploy Anywhere Works flawlessly on Vercel, Netlify, AWS Amplify Hosting, CloudFront + S3 Future-Proof This is the official AWS-recommended pattern from 2024 onward What You Will Build (Exact Outcome) A complete Next.js 14 (App Router) application with:\nSign-up ‚Üí automatic email verification code Sign-in ‚Üí protected dashboard Global AuthContext + useAuth() hook ProtectedRoute component Clean, modern UI using shadcn/ui Zero security anti-patterns Ready? You are now exactly on the same path that AWS solutions architects, startups, and enterprises use daily in 2025.\nNext Step: 5.2 Prerequisites ‚Üí Set up your AWS account, Node.js, and development environment\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.5-cognito-function/5.5.2-auth-ui/","title":"Build Authentication UI","tags":[],"description":"","content":"5.5.2 Build Authentication UI 100% faithful to your original workshop ‚Äî beautiful, functional, production-grade\nYou now have all the Cognito logic. Time to build the real user interface ‚Äî exactly as you wrote it in your workshop.\n1. Landing Page ‚Äì app/page.tsx // app/page.tsx import Link from \u0026#34;next/link\u0026#34;; import { Button } from \u0026#34;@/components/ui/button\u0026#34;; import { Card, CardContent, CardDescription, CardHeader, CardTitle } from \u0026#34;@/components/ui/card\u0026#34;; export default function HomePage() { return ( \u0026lt;div className=\u0026#34;min-h-screen flex items-center justify-center bg-gradient-to-br from-gray-50 to-gray-100\u0026#34;\u0026gt; \u0026lt;Card className=\u0026#34;w-full max-w-md\u0026#34;\u0026gt; \u0026lt;CardHeader className=\u0026#34;text-center\u0026#34;\u0026gt; \u0026lt;CardTitle className=\u0026#34;text-3xl font-bold\u0026#34;\u0026gt;Welcome\u0026lt;/CardTitle\u0026gt; \u0026lt;CardDescription\u0026gt;Secure file management system with user authentication\u0026lt;/CardDescription\u0026gt; \u0026lt;/CardHeader\u0026gt; \u0026lt;CardContent className=\u0026#34;space-y-4\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;grid gap-3\u0026#34;\u0026gt; \u0026lt;Button asChild size=\u0026#34;lg\u0026#34;\u0026gt; \u0026lt;Link href=\u0026#34;/signin\u0026#34;\u0026gt;Login\u0026lt;/Link\u0026gt; \u0026lt;/Button\u0026gt; \u0026lt;Button asChild variant=\u0026#34;outline\u0026#34; size=\u0026#34;lg\u0026#34;\u0026gt; \u0026lt;Link href=\u0026#34;/signup\u0026#34;\u0026gt;Sign Up\u0026lt;/Link\u0026gt; \u0026lt;/Button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;pt-4 border-t\u0026#34;\u0026gt; \u0026lt;p className=\u0026#34;text-sm text-muted-foreground text-center mb-3\u0026#34;\u0026gt;Protected Pages:\u0026lt;/p\u0026gt; \u0026lt;div className=\u0026#34;grid gap-2\u0026#34;\u0026gt; \u0026lt;Button asChild variant=\u0026#34;secondary\u0026#34; size=\u0026#34;sm\u0026#34;\u0026gt; \u0026lt;Link href=\u0026#34;/dashboard\u0026#34;\u0026gt;Dashboard\u0026lt;/Link\u0026gt; \u0026lt;/Button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/CardContent\u0026gt; \u0026lt;/Card\u0026gt; \u0026lt;/div\u0026gt; ); } 2. Sign-Up Page (with Email Verification) ‚Äì app/signup/page.tsx \u0026#39;use client\u0026#39;; import { useState } from \u0026#39;react\u0026#39;; import { useRouter } from \u0026#39;next/navigation\u0026#39;; import { cognitoSignUp, cognitoConfirmSignUp } from \u0026#39;@/lib/cognito-auth\u0026#39;; export default function SignUpPage() { const router = useRouter(); const [step, setStep] = useState\u0026lt;\u0026#39;signup\u0026#39; | \u0026#39;confirm\u0026#39;\u0026gt;(\u0026#39;signup\u0026#39;); const [email, setEmail] = useState(\u0026#39;\u0026#39;); const [password, setPassword] = useState(\u0026#39;\u0026#39;); const [name, setName] = useState(\u0026#39;\u0026#39;); const [code, setCode] = useState(\u0026#39;\u0026#39;); const [error, setError] = useState(\u0026#39;\u0026#39;); const [loading, setLoading] = useState(false); const handleSignUp = async (e: React.FormEvent) =\u0026gt; { e.preventDefault(); setError(\u0026#39;\u0026#39;); setLoading(true); const result = await cognitoSignUp({ email, password, name }); setLoading(false); if (result.success) { setStep(\u0026#39;confirm\u0026#39;); } else { setError(result.error || \u0026#39;Sign up failed\u0026#39;); } }; const handleConfirm = async (e: React.FormEvent) =\u0026gt; { e.preventDefault(); setError(\u0026#39;\u0026#39;); setLoading(true); const result = await cognitoConfirmSignUp(email, code); setLoading(false); if (result.success) { router.push(\u0026#39;/signin\u0026#39;); } else { setError(result.error || \u0026#39;Verification failed\u0026#39;); } }; // Confirmation Step if (step === \u0026#39;confirm\u0026#39;) { return ( \u0026lt;div className=\u0026#34;min-h-screen flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;max-w-md w-full p-8 bg-white rounded-lg shadow-lg\u0026#34;\u0026gt; \u0026lt;h1 className=\u0026#34;text-2xl font-bold mb-6\u0026#34;\u0026gt;Verify Email\u0026lt;/h1\u0026gt; \u0026lt;p className=\u0026#34;mb-4 text-gray-600\u0026#34;\u0026gt;Enter the verification code sent to {email}\u0026lt;/p\u0026gt; \u0026lt;form onSubmit={handleConfirm}\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Verification Code\u0026#34; value={code} onChange={(e) =\u0026gt; setCode(e.target.value)} className=\u0026#34;w-full px-4 py-2 border rounded-lg mb-4\u0026#34; required /\u0026gt; {error \u0026amp;\u0026amp; \u0026lt;p className=\u0026#34;text-red-500 mb-4\u0026#34;\u0026gt;{error}\u0026lt;/p\u0026gt;} \u0026lt;button type=\u0026#34;submit\u0026#34; disabled={loading} className=\u0026#34;w-full bg-blue-600 text-white py-2 rounded-lg hover:bg-blue-700 disabled:opacity-50\u0026#34; \u0026gt; {loading ? \u0026#39;Verifying...\u0026#39; : \u0026#39;Verify Email\u0026#39;} \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } // Sign-Up Form return ( \u0026lt;div className=\u0026#34;min-h-screen flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;max-w-md w-full p-8 bg-white rounded-lg shadow-lg\u0026#34;\u0026gt; \u0026lt;h1 className=\u0026#34;text-2xl font-bold mb-6\u0026#34;\u0026gt;Sign Up\u0026lt;/h1\u0026gt; \u0026lt;form onSubmit={handleSignUp}\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Full Name\u0026#34; value={name} onChange={(e) =\u0026gt; setName(e.target.value)} className=\u0026#34;w-full px-4 py-2 border rounded-lg mb-4\u0026#34; required /\u0026gt; \u0026lt;input type=\u0026#34;email\u0026#34; placeholder=\u0026#34;Email\u0026#34; value={email} onChange={(e) =\u0026gt; setEmail(e.target.value)} className=\u0026#34;w-full px-4 py-2 border rounded-lg mb-4\u0026#34; required /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; placeholder=\u0026#34;Password\u0026#34; value={password} onChange={(e) =\u0026gt; setPassword(e.target.value)} className=\u0026#34;w-full px-4 py-2 border rounded-lg mb-4\u0026#34; required /\u0026gt; \u0026lt;p className=\u0026#34;text-xs text-gray-500 mb-4\u0026#34;\u0026gt; Password must be at least 8 characters with uppercase, lowercase, number, and special character \u0026lt;/p\u0026gt; {error \u0026amp;\u0026amp; \u0026lt;p className=\u0026#34;text-red-500 mb-4\u0026#34;\u0026gt;{error}\u0026lt;/p\u0026gt;} \u0026lt;button type=\u0026#34;submit\u0026#34; disabled={loading} className=\u0026#34;w-full bg-blue-600 text-white py-2 rounded-lg hover:bg-blue-700 disabled:opacity-50\u0026#34; \u0026gt; {loading ? \u0026#39;Signing up...\u0026#39; : \u0026#39;Sign Up\u0026#39;} \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } 3. Sign-In Page ‚Äì app/signin/page.tsx \u0026#39;use client\u0026#39;; import { useState } from \u0026#39;react\u0026#39;; import { useRouter } from \u0026#39;next/navigation\u0026#39;; import { cognitoSignIn } from \u0026#39;@/lib/cognito-auth\u0026#39;; export default function LoginPage() { const router = useRouter(); const [email, setEmail] = useState(\u0026#39;\u0026#39;); const [password, setPassword] = useState(\u0026#39;\u0026#39;); const [error, setError] = useState(\u0026#39;\u0026#39;); const [loading, setLoading] = useState(false); const handleSubmit = async (e: React.FormEvent) =\u0026gt; { e.preventDefault(); setError(\u0026#39;\u0026#39;); setLoading(true); const result = await cognitoSignIn({ email, password }); setLoading(false); if (result.success) { router.push(\u0026#39;/dashboard\u0026#39;); } else { setError(result.error || \u0026#39;Login failed\u0026#39;); } }; return ( \u0026lt;div className=\u0026#34;min-h-screen flex items-center justify-center bg-gray-50\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;max-w-md w-full p-8 bg-white rounded-lg shadow-lg\u0026#34;\u0026gt; \u0026lt;h1 className=\u0026#34;text-3xl font-bold mb-6 text-center\u0026#34;\u0026gt;Sign In\u0026lt;/h1\u0026gt; \u0026lt;form onSubmit={handleSubmit}\u0026gt; \u0026lt;div className=\u0026#34;mb-4\u0026#34;\u0026gt; \u0026lt;label className=\u0026#34;block text-gray-700 mb-2\u0026#34;\u0026gt;Email\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;email\u0026#34; value={email} onChange={(e) =\u0026gt; setEmail(e.target.value)} className=\u0026#34;w-full px-4 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500\u0026#34; required /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;mb-6\u0026#34;\u0026gt; \u0026lt;label className=\u0026#34;block text-gray-700 mb-2\u0026#34;\u0026gt;Password\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; value={password} onChange={(e) =\u0026gt; setPassword(e.target.value)} className=\u0026#34;w-full px-4 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500\u0026#34; required /\u0026gt; \u0026lt;/div\u0026gt; {error \u0026amp;\u0026amp; \u0026lt;div className=\u0026#34;mb-4 p-3 bg-red-100 border border-red-400 text-red-700 rounded-lg\u0026#34;\u0026gt;{error}\u0026lt;/div\u0026gt;} \u0026lt;button type=\u0026#34;submit\u0026#34; disabled={loading} className=\u0026#34;w-full bg-blue-600 text-white py-3 rounded-lg font-semibold hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed transition\u0026#34; \u0026gt; {loading ? \u0026#39;Signing in...\u0026#39; : \u0026#39;Sign In\u0026#39;} \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;div className=\u0026#34;mt-6 text-center\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;/signup\u0026#34; className=\u0026#34;text-blue-600 hover:underline\u0026#34;\u0026gt;Don\u0026#39;t have an account? Sign up\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;mt-2 text-center\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;/forgot-password\u0026#34; className=\u0026#34;text-gray-600 hover:underline text-sm\u0026#34;\u0026gt;Forgot password?\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } 4. forgot and change password - app/forgot-password/page.tsx \u0026#39;use client\u0026#39;; import { useState } from \u0026#39;react\u0026#39;; import { useRouter } from \u0026#39;next/navigation\u0026#39;; import Link from \u0026#39;next/link\u0026#39;; import { cognitoResetPassword, cognitoConfirmResetPassword } from \u0026#39;@/lib/cognito-auth\u0026#39;; import { Button } from \u0026#39;@/components/ui/button\u0026#39;; import { Input } from \u0026#39;@/components/ui/input\u0026#39;; import { Label } from \u0026#39;@/components/ui/label\u0026#39;; import { Card, CardContent, CardDescription, CardHeader, CardTitle } from \u0026#39;@/components/ui/card\u0026#39;; import { Alert, AlertDescription } from \u0026#39;@/components/ui/alert\u0026#39;; export default function ForgotPasswordPage() { const [step, setStep] = useState\u0026lt;\u0026#39;request\u0026#39; | \u0026#39;confirm\u0026#39;\u0026gt;(\u0026#39;request\u0026#39;); const [email, setEmail] = useState(\u0026#39;\u0026#39;); const [code, setCode] = useState(\u0026#39;\u0026#39;); const [newPassword, setNewPassword] = useState(\u0026#39;\u0026#39;); const [confirmPassword, setConfirmPassword] = useState(\u0026#39;\u0026#39;); const [error, setError] = useState(\u0026#39;\u0026#39;); const [success, setSuccess] = useState(\u0026#39;\u0026#39;); const [loading, setLoading] = useState(false); const router = useRouter(); const handleRequestReset = async (e: React.FormEvent) =\u0026gt; { e.preventDefault(); setError(\u0026#39;\u0026#39;); setSuccess(\u0026#39;\u0026#39;); setLoading(true); try { const result = await cognitoResetPassword(email); if (result.success) { setSuccess(result.message || \u0026#39;Password reset code sent to your email\u0026#39;); setStep(\u0026#39;confirm\u0026#39;); } else { setError(result.error || \u0026#39;Failed to send reset code\u0026#39;); } } catch (err: any) { setError(err.message || \u0026#39;An error occurred\u0026#39;); } finally { setLoading(false); } }; const handleConfirmReset = async (e: React.FormEvent) =\u0026gt; { e.preventDefault(); setError(\u0026#39;\u0026#39;); setSuccess(\u0026#39;\u0026#39;); if (newPassword !== confirmPassword) { setError(\u0026#39;Passwords do not match\u0026#39;); return; } if (newPassword.length \u0026lt; üòé { setError(\u0026#39;Password must be at least 8 characters long\u0026#39;); return; } setLoading(true); try { const result = await cognitoConfirmResetPassword( email, code, newPassword, ); if (result.success) { setSuccess(\u0026#39;Password reset successful! Redirecting to login...\u0026#39;); setTimeout(() =\u0026gt; { router.push(\u0026#39;/signin\u0026#39;); }, 2000); } else { setError(result.error || \u0026#39;Failed to reset password\u0026#39;); } } catch (err: any) { setError(err.message || \u0026#39;An error occurred\u0026#39;); } finally { setLoading(false); } }; if (step === \u0026#39;confirm\u0026#39;) { return ( \u0026lt;div className=\u0026#34;min-h-screen flex items-center justify-center bg-gradient-to-br from-blue-50 to-indigo-100 px-4\u0026#34;\u0026gt; \u0026lt;Card className=\u0026#34;w-full max-w-md\u0026#34;\u0026gt; \u0026lt;CardHeader className=\u0026#34;space-y-1\u0026#34;\u0026gt; \u0026lt;CardTitle className=\u0026#34;text-2xl font-bold text-center\u0026#34;\u0026gt;Reset Password\u0026lt;/CardTitle\u0026gt; \u0026lt;CardDescription className=\u0026#34;text-center\u0026#34;\u0026gt; Enter the code sent to {email} and your new password \u0026lt;/CardDescription\u0026gt; \u0026lt;/CardHeader\u0026gt; \u0026lt;CardContent\u0026gt; \u0026lt;form onSubmit={handleConfirmReset} className=\u0026#34;space-y-4\u0026#34;\u0026gt; {error \u0026amp;\u0026amp; ( \u0026lt;Alert variant=\u0026#34;destructive\u0026#34;\u0026gt; \u0026lt;AlertDescription\u0026gt;{error}\u0026lt;/AlertDescription\u0026gt; \u0026lt;/Alert\u0026gt; )} {success \u0026amp;\u0026amp; ( \u0026lt;Alert className=\u0026#34;bg-green-50 border-green-200\u0026#34;\u0026gt; \u0026lt;AlertDescription className=\u0026#34;text-green-800\u0026#34;\u0026gt;{success}\u0026lt;/AlertDescription\u0026gt; \u0026lt;/Alert\u0026gt; )} \u0026lt;div className=\u0026#34;space-y-2\u0026#34;\u0026gt; \u0026lt;Label htmlFor=\u0026#34;code\u0026#34;\u0026gt;Verification Code\u0026lt;/Label\u0026gt; \u0026lt;Input id=\u0026#34;code\u0026#34; type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Enter 6-digit code\u0026#34; value={code} onChange={(e) =\u0026gt; setCode(e.target.value)} required disabled={loading} maxLength={6} /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;space-y-2\u0026#34;\u0026gt; \u0026lt;Label htmlFor=\u0026#34;newPassword\u0026#34;\u0026gt;New Password\u0026lt;/Label\u0026gt; \u0026lt;Input id=\u0026#34;newPassword\u0026#34; type=\u0026#34;password\u0026#34; placeholder=\u0026#34;‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢\u0026#34; value={newPassword} onChange={(e) =\u0026gt; setNewPassword(e.target.value)} required disabled={loading} /\u0026gt; \u0026lt;p className=\u0026#34;text-xs text-gray-500\u0026#34;\u0026gt; Must be at least 8 characters with uppercase, lowercase, number, and special character \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;space-y-2\u0026#34;\u0026gt; \u0026lt;Label htmlFor=\u0026#34;confirmPassword\u0026#34;\u0026gt;Confirm New Password\u0026lt;/Label\u0026gt; \u0026lt;Input id=\u0026#34;confirmPassword\u0026#34; type=\u0026#34;password\u0026#34; placeholder=\u0026#34;‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢\u0026#34; value={confirmPassword} onChange={(e) =\u0026gt; setConfirmPassword(e.target.value)} required disabled={loading} /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;Button type=\u0026#34;submit\u0026#34; className=\u0026#34;w-full\u0026#34; disabled={loading}\u0026gt; {loading ? \u0026#39;Resetting...\u0026#39; : \u0026#39;Reset Password\u0026#39;} \u0026lt;/Button\u0026gt; \u0026lt;div className=\u0026#34;text-center text-sm text-gray-600\u0026#34;\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; onClick={() =\u0026gt; setStep(\u0026#39;request\u0026#39;)} className=\u0026#34;text-blue-600 hover:underline\u0026#34; \u0026gt; Back to request reset \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/CardContent\u0026gt; \u0026lt;/Card\u0026gt; \u0026lt;/div\u0026gt; ); } return ( \u0026lt;div className=\u0026#34;min-h-screen flex items-center justify-center bg-gradient-to-br from-blue-50 to-indigo-100 px-4\u0026#34;\u0026gt; \u0026lt;Card className=\u0026#34;w-full max-w-md\u0026#34;\u0026gt; \u0026lt;CardHeader className=\u0026#34;space-y-1\u0026#34;\u0026gt; \u0026lt;CardTitle className=\u0026#34;text-2xl font-bold text-center\u0026#34;\u0026gt;Forgot Password\u0026lt;/CardTitle\u0026gt; \u0026lt;CardDescription className=\u0026#34;text-center\u0026#34;\u0026gt; Enter your email to receive a password reset code \u0026lt;/CardDescription\u0026gt; \u0026lt;/CardHeader\u0026gt; \u0026lt;CardContent\u0026gt; \u0026lt;form onSubmit={handleRequestReset} className=\u0026#34;space-y-4\u0026#34;\u0026gt; {error \u0026amp;\u0026amp; ( \u0026lt;Alert variant=\u0026#34;destructive\u0026#34;\u0026gt; \u0026lt;AlertDescription\u0026gt;{error}\u0026lt;/AlertDescription\u0026gt; \u0026lt;/Alert\u0026gt; )} {success \u0026amp;\u0026amp; ( \u0026lt;Alert className=\u0026#34;bg-green-50 border-green-200\u0026#34;\u0026gt; \u0026lt;AlertDescription className=\u0026#34;text-green-800\u0026#34;\u0026gt;{success}\u0026lt;/AlertDescription\u0026gt; \u0026lt;/Alert\u0026gt; )} \u0026lt;div className=\u0026#34;space-y-2\u0026#34;\u0026gt; \u0026lt;Label htmlFor=\u0026#34;email\u0026#34;\u0026gt;Email\u0026lt;/Label\u0026gt; \u0026lt;Input id=\u0026#34;email\u0026#34; type=\u0026#34;email\u0026#34; placeholder=\u0026#34;you@example.com\u0026#34; value={email} onChange={(e) =\u0026gt; setEmail(e.target.value)} required disabled={loading} /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;Button type=\u0026#34;submit\u0026#34; className=\u0026#34;w-full\u0026#34; disabled={loading}\u0026gt; {loading ? \u0026#39;Sending...\u0026#39; : \u0026#39;Send Reset Code\u0026#39;} \u0026lt;/Button\u0026gt; \u0026lt;div className=\u0026#34;text-center text-sm text-gray-600\u0026#34;\u0026gt; Remember your password?{\u0026#39; \u0026#39;} \u0026lt;Link href=\u0026#34;/signin\u0026#34; className=\u0026#34;text-blue-600 hover:underline font-medium\u0026#34;\u0026gt; Sign in \u0026lt;/Link\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/CardContent\u0026gt; \u0026lt;/Card\u0026gt; \u0026lt;/div\u0026gt; ); } 5. Dashboard Page ‚Äì app/dashboard/page.tsx \u0026#39;use client\u0026#39;; import { ProtectedRoute } from \u0026#34;@/components/ProtectedRoute\u0026#34;; import { useAuth } from \u0026#34;@/context/AuthContext\u0026#34;; import { LogOut, User, Mail, Shield, KeyRound, ArrowRight } from \u0026#34;lucide-react\u0026#34;; import Link from \u0026#34;next/link\u0026#34;; export default function DashboardPage() { const { user, signOut } = useAuth(); const handleSignOut = async () =\u0026gt; { await signOut(); }; return ( \u0026lt;ProtectedRoute\u0026gt; \u0026lt;div className=\u0026#34;min-h-screen bg-gradient-to-br from-background via-background to-secondary/5\u0026#34;\u0026gt; {/* Header */} \u0026lt;header className=\u0026#34;border-b border-border/50 backdrop-blur-sm sticky top-0 z-50\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;max-w-6xl mx-auto px-6 py-4 flex items-center justify-between\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex items-center gap-3\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-10 h-10 rounded-lg bg-gradient-to-br from-primary to-primary/60 flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;User className=\u0026#34;w-6 h-6 text-primary-foreground\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h1 className=\u0026#34;text-xl font-bold text-foreground\u0026#34;\u0026gt;Dashboard\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button onClick={handleSignOut} className=\u0026#34;inline-flex items-center gap-2 px-4 py-2 rounded-lg text-sm font-medium bg-destructive/10 text-destructive hover:bg-destructive/20 transition-colors\u0026#34;\u0026gt; \u0026lt;LogOut className=\u0026#34;w-4 h-4\u0026#34; /\u0026gt; Sign Out \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/header\u0026gt; {/* Main Content */} \u0026lt;main className=\u0026#34;max-w-6xl mx-auto px-6 py-12\u0026#34;\u0026gt; {/* Welcome + Stats */} \u0026lt;div className=\u0026#34;mb-12\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;space-y-2 mb-8\u0026#34;\u0026gt; \u0026lt;h2 className=\u0026#34;text-4xl font-bold text-foreground\u0026#34;\u0026gt;Welcome back\u0026lt;/h2\u0026gt; \u0026lt;p className=\u0026#34;text-lg text-muted-foreground\u0026#34;\u0026gt;{user?.name || user?.email}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;grid grid-cols-1 md:grid-cols-3 gap-6\u0026#34;\u0026gt; {/* Account Status */} \u0026lt;div className=\u0026#34;group relative overflow-hidden rounded-2xl bg-card border border-border/50 p-6 hover:shadow-lg transition-shadow duration-300\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;absolute inset-0 bg-gradient-to-br from-primary/5 to-transparent opacity-0 group-hover:opacity-100 transition-opacity\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;relative space-y-4\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-12 h-12 rounded-xl bg-primary/10 flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;Shield className=\u0026#34;w-6 h-6 text-primary\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3 className=\u0026#34;text-sm font-semibold text-muted-foreground uppercase tracking-wide\u0026#34;\u0026gt;Account Status\u0026lt;/h3\u0026gt; \u0026lt;p className=\u0026#34;text-2xl font-bold text-foreground mt-2\u0026#34;\u0026gt;Active\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/* Role */} \u0026lt;div className=\u0026#34;group relative overflow-hidden rounded-2xl bg-card border border-border/50 p-6 hover:shadow-lg transition-shadow duration-300\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;absolute inset-0 bg-gradient-to-br from-accent/5 to-transparent opacity-0 group-hover:opacity-100 transition-opacity\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;relative space-y-4\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-12 h-12 rounded-xl bg-accent/10 flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;User className=\u0026#34;w-6 h-6 text-accent\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3 className=\u0026#34;text-sm font-semibold text-muted-foreground uppercase tracking-wide\u0026#34;\u0026gt;User Role\u0026lt;/h3\u0026gt; \u0026lt;p className=\u0026#34;text-2xl font-bold text-foreground mt-2 capitalize\u0026#34;\u0026gt;{user?.role || \u0026#34;Member\u0026#34;}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/* Email Status */} \u0026lt;div className=\u0026#34;group relative overflow-hidden rounded-2xl bg-card border border-border/50 p-6 hover:shadow-lg transition-shadow duration-300\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;absolute inset-0 bg-gradient-to-br from-chart-1/5 to-transparent opacity-0 group-hover:opacity-100 transition-opacity\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;relative space-y-4\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-12 h-12 rounded-xl bg-chart-1/10 flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;Mail className=\u0026#34;w-6 h-6 text-chart-1\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3 className=\u0026#34;text-sm font-semibold text-muted-foreground uppercase tracking-wide\u0026#34;\u0026gt;Email Status\u0026lt;/h3\u0026gt; \u0026lt;p className=\u0026#34;text-2xl font-bold text-foreground mt-2\u0026#34;\u0026gt;Verified\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/* User Info + Actions */} \u0026lt;div className=\u0026#34;grid grid-cols-1 lg:grid-cols-3 gap-6\u0026#34;\u0026gt; {/* Main Card */} \u0026lt;div className=\u0026#34;lg:col-span-2 rounded-2xl bg-card border border-border/50 overflow-hidden hover:shadow-lg transition-shadow duration-300\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;h-24 bg-gradient-to-r from-primary to-accent/50\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;p-8 -mt-12 relative\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;mb-8\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-24 h-24 rounded-2xl bg-card border-4 border-background shadow-lg flex items-center justify-center mb-6\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-full h-full bg-gradient-to-br from-primary/20 to-accent/20 rounded-xl flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;User className=\u0026#34;w-12 h-12 text-primary\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h3 className=\u0026#34;text-2xl font-bold text-foreground\u0026#34;\u0026gt;{user?.name || user?.email}\u0026lt;/h3\u0026gt; \u0026lt;p className=\u0026#34;text-muted-foreground mt-1\u0026#34;\u0026gt;Authenticated User\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;space-y-4 pt-8 border-t border-border/50\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex items-start gap-4\u0026#34;\u0026gt; \u0026lt;Mail className=\u0026#34;w-5 h-5 text-primary mt-1 flex-shrink-0\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;flex-1 min-w-0\u0026#34;\u0026gt; \u0026lt;p className=\u0026#34;text-sm text-muted-foreground\u0026#34;\u0026gt;Email Address\u0026lt;/p\u0026gt; \u0026lt;p className=\u0026#34;text-foreground font-medium break-all\u0026#34;\u0026gt;{user?.email}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;flex items-start gap-4\u0026#34;\u0026gt; \u0026lt;Shield className=\u0026#34;w-5 h-5 text-accent mt-1 flex-shrink-0\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;flex-1\u0026#34;\u0026gt; \u0026lt;p className=\u0026#34;text-sm text-muted-foreground\u0026#34;\u0026gt;User ID\u0026lt;/p\u0026gt; \u0026lt;p className=\u0026#34;text-foreground font-medium font-mono text-sm\u0026#34;\u0026gt;{user?.userId || \u0026#34;N/A\u0026#34;}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;flex items-start gap-4\u0026#34;\u0026gt; \u0026lt;User className=\u0026#34;w-5 h-5 text-chart-1 mt-1 flex-shrink-0\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;flex-1\u0026#34;\u0026gt; \u0026lt;p className=\u0026#34;text-sm text-muted-foreground\u0026#34;\u0026gt;Account Role\u0026lt;/p\u0026gt; \u0026lt;p className=\u0026#34;text-foreground font-medium capitalize\u0026#34;\u0026gt;{user?.role || \u0026#34;Member\u0026#34;}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/* Actions */} \u0026lt;div className=\u0026#34;space-y-4\u0026#34;\u0026gt; \u0026lt;Link href=\u0026#34;/forgot-password\u0026#34; className=\u0026#34;flex items-center justify-between gap-3 p-4 rounded-xl bg-card border border-border/50 hover:bg-secondary/50 hover:border-border transition-all duration-200 group\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex items-center gap-3\u0026#34;\u0026gt; \u0026lt;KeyRound className=\u0026#34;w-5 h-5 text-primary\u0026#34; /\u0026gt; \u0026lt;span className=\u0026#34;font-medium text-foreground\u0026#34;\u0026gt;Change Password\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;ArrowRight className=\u0026#34;w-4 h-4 text-muted-foreground group-hover:translate-x-1 transition-transform\u0026#34; /\u0026gt; \u0026lt;/Link\u0026gt; \u0026lt;button onClick={handleSignOut} className=\u0026#34;w-full flex items-center justify-between gap-3 p-4 rounded-xl bg-destructive/10 border border-destructive/20 hover:bg-destructive/20 transition-all duration-200 group\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex items-center gap-3\u0026#34;\u0026gt; \u0026lt;LogOut className=\u0026#34;w-5 h-5 text-destructive\u0026#34; /\u0026gt; \u0026lt;span className=\u0026#34;font-medium text-destructive\u0026#34;\u0026gt;Sign Out\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;ArrowRight className=\u0026#34;w-4 h-4 text-destructive/50 group-hover:translate-x-1 transition-transform\u0026#34; /\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/ProtectedRoute\u0026gt; ); } You now have a stunning, fully working authentication UI ‚Äî exactly as you designed it.\nNavigation:\nPrevious: 5.5.1 Create Authentication Functions Next Step: 5.5.3 Implement Protected Routes ‚Üí Add route protection and authentication middleware "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.3-aws-cognito/5.3.2-configure-appclient/","title":"Configure App Client","tags":[],"description":"","content":"Configure Application client Open Cloud Shell aws cognito-idp create-user-pool-client \\ --user-pool-id us-east-1_xxxxxxx \\ --client-name WebApp-NoSecret \\ --no-generate-secret \\ --callback-urls \u0026#39;[\u0026#34;http://localhost:3000/\u0026#34;]\u0026#39; \\ --logout-urls \u0026#39;[\u0026#34;http://localhost:3000/\u0026#34;]\u0026#39; \\ --query \u0026#39;UserPoolClient.ClientId\u0026#39; --output text Example output: h1a234example123 you give userpood id to line, then enter you will create AppClient that do no generate secret\nNavigation:\nPrevious: 5.3.1 Create Cognito User Pool Next Step: 5.4 Next.js Project Setup ‚Üí Set up Next.js and Amplify SDK "},{"uri":"https://thormastran.github.io/fcj-workshop-template/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nSummary Report: ‚ÄúAI/ML/GenAI on AWS‚Äù Event Objectives Gain a clear understanding of AWS AI/ML and Generative AI ecosystem Hands-on exposure to Amazon SageMaker and Amazon Bedrock through live demos Master core Generative AI concepts: Prompt Engineering, RAG, Agents, and Guardrails Identify quick-win GenAI use cases suitable for Vietnamese enterprises Speakers AWS Vietnam Team AWS Specialist Solutions Architect ‚Äì Machine Learning AWS Senior Specialist Solutions Architect ‚Äì Generative AI Key Highlights Amazon SageMaker ‚Äì Full-lifecycle ML Platform End-to-end workflow: data preparation \u0026amp; labeling ‚Üí model training \u0026amp; tuning ‚Üí deployment ‚Üí monitoring SageMaker Studio: the most productive IDE for data scientists and ML engineers today Built-in MLOps tools (Feature Store, Model Registry, Pipelines) ‚Äî no third-party tools required Live demo: trained and deployed an image classification model in under 15 minutes Generative AI with Amazon Bedrock (the most practical session) Serverless access to leading Foundation Models: Claude 3 (Haiku/Sonnet/Opus), Llama 3, Titan Detailed comparison of speed, quality, and cost ‚Üí clear guidance on model selection Advanced Prompt Engineering: Chain-of-Thought, Few-shot, ReAct, Tool Use Retrieval-Augmented Generation (RAG) + Knowledge Bases: the most cost-effective way to ground LLMs with private data Bedrock Agents: turn chatbots into autonomous agents that call APIs, query databases, and execute multi-step tasks Guardrails: built-in content filtering, brand safety, and compliance controls Highlight live demo: built a fully functional enterprise chatbot with RAG + Knowledge Base + Guardrails in ~20 minutes Key Takeaways Prompt Engineering is the #1 skill for 2025‚Äì2026 RAG is mandatory if you want accurate, hallucination-free answers on your own data Bedrock Agents + Tool Integration move GenAI from ‚Äúcool demo‚Äù to real production applications Vietnamese companies can now go from idea to production GenAI app in weeks, not months 027- Bedrock pricing is extremely competitive ‚Äî often cheaper than self-hosting open-source models when infrastructure is factored in Applying to Work (Action Plan) Next week: start experimenting with Bedrock Playground and SageMaker Studio (Free Tier is sufficient) December 2025: run internal Prompt Engineering + RAG workshop for the team Q1 2026: pilot at least one internal GenAI project (e.g., HR/policy/product knowledge chatbot using Bedrock + RAG) Integrate Amazon Q Developer into daily development workflow for 20‚Äì30% productivity gain Event Experience Extremely hands-on and production-focused: ~70% live coding/demo, ~30% Q\u0026amp;A. No fluffy slides ‚Äî everything shown was reproducible on the spot. The Bedrock demo was mind-blowing: a complete enterprise-ready GenAI application with private data integration built in just 20 minutes ‚Äî something that used to take teams months.\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.4-next.js-setup/5.4.2-install-amplify/","title":"Install Amplify SDK and Configure Amplify","tags":[],"description":"","content":"Install Amplify SDK After preparing your Next.js project, install the necessary Amplify packages:\nnpm install aws-amplify @aws-amplify/ui-react 2. Create the Amplify Configuration File Create a new file:\nsrc/lib/amplify-config.ts\nAnd add the following code:\nimport { Amplify } from \u0026#39;aws-amplify\u0026#39;; export const amplifyConfig = { Auth: { Cognito: { userPoolId: process.env.NEXT_PUBLIC_COGNITO_USER_POOL_ID!, userPoolClientId: process.env.NEXT_PUBLIC_COGNITO_APP_CLIENT_ID!, loginWith: { username: false, email: true, }, }, }, }; // Configure Amplify with SSR support Amplify.configure(amplifyConfig, { ssr: true, // Important for Next.js }); 3. Add Environment Variables Create a .env.local file and paste your Cognito IDs:\nNEXT_PUBLIC_COGNITO_USER_POOL_ID=us-east-1_xxxxxxxxx NEXT_PUBLIC_COGNITO_APP_CLIENT_ID=xxxxxxxxxxxxxxxxxxxx This ensures Amplify is available across your entire application.\nAmplify is now configured and ready to be used for:\nSign up\nSign in\nSign out\nSession management\nProtected routes\nNext, you will build the UI for authentication.\nNavigation:\nPrevious: 5.4.1 Install Next.js Next Step: 5.5 Cognito Functions ‚Üí Build auth functions, UI, and protected routes "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.2-prerequiste/","title":"Prerequiste","tags":[],"description":"","content":"Prerequisites Before starting the workshop, ensure you have the following requirements ready.\n1. AWS Account \u0026amp; Permissions You need an AWS account to create and manage Cognito User Pools and work with Amplify.\nRequirements:\nAn AWS Account An IAM user (not root) with the following permissions: AmazonCognitoFullAccess IAMUserChangePassword AWSCloudFormationFullAccess AWSLambda_FullAccess (optional, for triggers) AmazonS3FullAccess (for optional hosting or storage) Steps:\nCreate an account at the AWS console. Create an IAM user with Programmatic access + Management Console. Configure your AWS region (recommended: us-east-1 or ap-southeast-1). 2. Local Development Environment Your local machine should be set up for building and running a Next.js + Amplify application.\nRequired Software Tool Version Purpose Node.js 18.x or later Required for Next.js \u0026amp; Amplify npm 9.x or later Package management Git Latest Version control Code Editor VS Code (recommended) Development AWS CLI (optional) Latest Useful for debugging and credentials setup Verify installation node --version # Should be v18.x or higher npm --version # Should be v9.x or higher git --version # Should show a valid version Navigation:\nPrevious: 5.1 Workshop Overview Next Step: 5.3 AWS Cognito Setup ‚Üí Create and configure Cognito User Pool "},{"uri":"https://thormastran.github.io/fcj-workshop-template/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Document version of the proposal\nRafilm: AI-Powered Movie Logging \u0026amp; Recommendation Platform A Serverless AWS Solution for Intelligent Movie Discovery 1. Executive Summary Rafilm is a Letterboxd-inspired movie logging and recommendation platform designed to help general users track their watched films, share reviews, and discover new favorites through AI-powered recommendations. Built as part of the AWS First Cloud Journey (FCJ) internship, Rafilm integrates Amazon Personalize and Bedrock to deliver tailored movie suggestions and conversational recommendations via a chatbot interface.\nThe platform runs fully on AWS Serverless architecture, featuring Amplify-hosted Next.js frontend, Lambda-based backend services connected through API Gateway, and DynamoDB for scalable user and movie data storage. TMDb provides external movie data integration, while Amazon Cognito manages user authentication. Rafilm aims to demonstrate a scalable, intelligent, and cost-efficient architecture capable of supporting multi-user access and interactive experiences.\n2. Problem Statement What‚Äôs the Problem? While existing movie platforms like Letterboxd and IMDb offer robust logging and social features, they lack personalized recommendation systems and interactive discovery experiences. Users often rely on external sources or generic trending lists to find what to watch next, leading to irrelevant or repetitive suggestions.\nThe Solution Rafilm integrates a custom recommendation pipeline powered by Amazon Personalize, combined with a Bedrock LLM chatbot that interprets user preferences and generates conversational movie recommendations. Users can log movies, write reviews, and receive curated suggestions‚Äîall within one seamless experience. Unlike Letterboxd, Rafilm focuses on data-driven personalization and AI-assisted interaction rather than pure social networking.\nBenefits and Return on Investment By leveraging AWS Serverless services, Rafilm achieves near-zero maintenance cost, pay-per-use scalability, and real-time AI-driven personalization. For the FCJ internship, the project serves as both a technical showcase and a learning artifact for integrating AI services in serverless architectures. Projected cost remains under $1/month during testing, with AWS Free Tier coverage for most usage.\n3. Solution Architecture Rafilm employs a modular serverless architecture using AWS services for scalability, integration, and cost optimization.\nAWS Services Used AWS Amplify: Hosts the Next.js frontend for movie browsing, logging, and chatbot interaction. Amazon Cognito: Handles user registration, login, and session management. Amazon API Gateway: Routes client requests to backend Lambda functions. AWS Lambda: Executes serverless business logic (e.g., CRUD for reviews, fetching TMDb data, triggering recommendations). Amazon DynamoDB: Stores user logs, movie interactions, and preferences. Amazon Personalize: Trains and serves personalized recommendation models. Amazon Bedrock: Provides conversational chatbot functionality for recommendation dialogue. Amazon S3: Stores static assets and backups for logs and model outputs. Component Design Frontend (Next.js): User-friendly interface for movie discovery, logging, and chat-based recommendations. Backend (Lambda + API Gateway): Stateless logic layer handling user operations, movie fetching, and recommendation retrieval. Data Layer (DynamoDB + S3): Stores structured user interactions and movie metadata for model training. AI Layer (Personalize + Bedrock): Personalize analyzes historical user interactions; Bedrock chatbot provides natural language access to personalized results. Authentication (Cognito): Securely manages multi-user access. Architecture Overview Users log in via Cognito and interact with the Next.js interface. Actions such as logging or rating trigger API Gateway ‚Üí Lambda ‚Üí DynamoDB workflows. The Bedrock chatbot accesses Personalize results to generate conversational movie suggestions. Amplify hosts the frontend for seamless deployment and scalability. 4. Technical Implementation Implementation Phases Architecture Design (Month 1): Research AWS serverless and AI integration patterns; finalize architecture diagrams. Prototype Integration (Month 2): Implement Amplify hosting, Cognito authentication, and Lambda-based backend APIs. Recommendation System (Month 3): Connect Personalize and Bedrock for end-to-end AI recommendation and chatbot response. Testing \u0026amp; Deployment: Conduct functional testing, optimize costs, and deploy production-ready version on Amplify. Technical Requirements Frontend: Next.js + React hosted via AWS Amplify, using TMDb API for movie data. Backend: AWS Lambda (Node.js runtime) connected through API Gateway. Database: Amazon DynamoDB for scalable user and review data. AI Components: Amazon Personalize (user-item recommendations) and Bedrock (chatbot dialogue). Authentication: Amazon Cognito for secure, multi-user access. Automation: AWS SDK \u0026amp; CloudFormation for provisioning; AWS SAM for deployment workflows. 5. Timeline \u0026amp; Milestones Phase Duration Key Deliverables Month 1 Research \u0026amp; Architecture AWS design finalizing Month 2 Core Development Amplify hosting, Cognito setup, Lambda API, DynamoDB schema Month 3 AI Integration \u0026amp; Testing Personalize training, Bedrock chatbot, system deployment Post-Launch Continuous Improvement Cost optimization, new features, UX refinement 6. Budget Estimation Estimated Monthly Cost: $40.09 USD ($481.08 for 12 months)\nThe cost estimate of this project is projected in this link: https://calculator.aws/#/estimate?id=dab7fb57dabfb76041cdba98ac2bac7ba9630046\nThe monthly cost estimate of $40.09 USD is calculated based on the following specific usage assumptions derived from the AWS Pricing Calculator:\nStandard Usage: Assumes 10,000 requests per month for both AWS Lambda and Amazon API Gateway. User Base: Assumes a maximum of 10,000 Monthly Active Users (MAU) for Amazon Cognito. AI/ML Usage (Primary Cost Driver): Amazon Bedrock is estimated for continuous operation (24 hours per day) with an average of 1 request per minute and 100 input/output tokens per request. Amazon Personalize includes 1 GB of data ingested and 15 training hours per month. Security Overhead: Assumes use of 1 AWS WAF Web ACL with 4 Rules and 3 Managed Rule Groups. Data Storage: Assumes 0.5 GB of data storage in Amazon DynamoDB. 7. Risk Assessment Risk Probability Impact Mitigation API rate limits from TMDb Medium Medium Cache requests via Lambda Model training cost escalation Low Medium Use limited training dataset for testing Chatbot latency Medium Low Optimize Bedrock model type and response size Authentication or token expiry Medium Low Use short-lived JWTs and refresh tokens 8. Expected Outcomes Technical Improvements Demonstrates serverless integration of AI/ML and LLM services in real-world use. Establishes a reusable AWS architecture for recommendation-based apps. Long-Term Value Provides a foundation for future expansion into a social movie discovery network. Serves as an AWS FCJ internship showcase project highlighting scalability, personalization, and conversational AI. "},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 10 Objectives: AWS WorkSpaces CloudFront with S3 Bucket , CLoud trail Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Prepare to deploy Amazon WorkSpaces - Access WorkSpaces - Browser - Access WorkSpaces - WorkSpaces Client 11/10/2025 11/10/2025 https://000093.awsstudygroup.com/4-access-to-amazon-workspaces/ 3 - CloudFront with S3 Bucket Origin 11/11/2025 11/11/2025 https://000094.awsstudygroup.com/ 4 - Use AWS Secrets Manager with Amazon RDS and AWS Fargate - Using on RDS 11/12/2025 11/12/2025 https://000096.awsstudygroup.com/3-rds-phase/ 5 - Continuously audit and limit Security Groups with AWS Firewall Manager + Security Groups + AWS Firewall Manager + Manage Security Group 11/13/2025 11/13/2025 https://000097.awsstudygroup.com/ 6 - Getting hands on with Amazon GuardDuty 11/14/2025 11/14/2025 https://000098.awsstudygroup.com/ Week 10 Achievements: Deployed and configured Amazon WorkSpaces for virtual desktop infrastructure:\nPrepared and deployed Amazon WorkSpaces with proper directory services setup. Successfully accessed WorkSpaces through browser-based client. Configured and tested WorkSpaces desktop client for enhanced user experience. Implemented CloudFront with S3 bucket for global content delivery:\nCreated CloudFront distribution with S3 bucket as origin. Configured caching policies and distribution settings for optimal performance. Tested content delivery and validated CDN functionality across different regions. Secured database credentials using AWS Secrets Manager:\nIntegrated AWS Secrets Manager with Amazon RDS for automatic credential rotation. Configured AWS Fargate applications to retrieve database secrets securely. Implemented best practices for secrets management in containerized environments. Overall: Completed comprehensive security and infrastructure workshops covering virtual desktops, content delivery, secrets management, network security, and threat detection.\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 11 Objectives: AWS Elastic Disaster Recovery Workshop Database Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Implement AutoScaling for WordPress Instance 11/17/2025 11/17/2025 https://000101.awsstudygroup.com/4-asgforec2/ 3 - Initialize AMI from WebServer Instance + Launch Template + Create Load Balancer + Create Auto Scaling Group + Database + \u0026hellip; 11/18/2025 11/18/2025 https://000101.awsstudygroup.com/4-asgforec2/4.5-createasg/ 4 - Backup and Restore Database - Practice: + Create DB Snapshot + Restore with DB Snapshot 11/19/2025 11/19/2025 https://000101.awsstudygroup.com/5-backupandrestore/5.2-restorewithsnapshot/ 5 - Create CloudFront for Web Server 11/20/2025 11/20/2025 https://000101.awsstudygroup.com/6-createcloudfront/ 6 - Introduction to Infrastructure as Code 11/21/2025 11/21/2025 https://000102.awsstudygroup.com/2-pre/ Week 11 Achievements: Implemented Auto Scaling for WordPress instances to handle traffic fluctuations:\nConfigured Auto Scaling policies based on CPU utilization and other metrics. Set up scaling triggers and thresholds for automatic instance provisioning. Tested scaling behavior under various load conditions. Created scalable web infrastructure with AMI and Load Balancer:\nGenerated custom AMI from configured web server instance. Designed and implemented Launch Template with proper instance configurations. Deployed Application Load Balancer for traffic distribution across instances. Successfully created and configured Auto Scaling Group for high availability. Mastered database backup and disaster recovery procedures:\nCreated automated and manual database snapshots for point-in-time recovery. Practiced database restoration from snapshots with minimal downtime. Implemented backup retention policies and cross-region backup strategies. Validated data integrity and consistency after restoration processes. Overall: Completed comprehensive disaster recovery and scalability workshop covering auto scaling, database backup/restore, content delivery acceleration, and infrastructure automation foundations.\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 12 Objectives: DEPLOY APPLICATION USING BEANSTALK . DEPLOY WEB APP WITH ELASTIC BEANSTALK AND CDK PIPELINES. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Set up Cognito AWS + amplify SDK + S3 11/24/2025 11/24/2025 3 - DEPLOY APPLICATION USING BEANSTALK + Application: + Application Environments + Isolated + Scalability + Elastic Load Balancing 11/25/2025 11/25/2025 https://000112.awsstudygroup.com/1-introduce/ 4 - DEPLOY WEB APP WITH ELASTIC BEANSTALK AND CDK PIPELINES - BUILD WEB APPLICATION - Practice: + CREATE INSFRATRUCTURE USING CDK + ADD THE ELASTIC BEANSTALK CDK + CREATE CICD PIPELINE STACK 11/26/2025 11/26/2025 https://000113.awsstudygroup.com/1-introduction/ 5 - AWS CLOUDFRONT WORKSHOP 11/27/2025 11/17/2025 https://cloudjourney.awsstudygroup.com/ 6 - SERVERLESS - CI/CD WITH CODEPIPELINE 11/28/2025 11/28/2025 https://000140.awsstudygroup.com/1-introduction/ Week 12 Achievements: Successfully set up and configured AWS Cognito for user authentication:\nCreated Cognito User Pool with custom configurations Integrated Amplify SDK for seamless authentication flow Mastered AWS Elastic Beanstalk application deployment:\nCreated and configured Elastic Beanstalk applications Set up multiple application environments (development, staging, production) Implemented advanced deployment with CDK Pipelines:\nBuilt comprehensive web applications using modern frameworks Created infrastructure as code using AWS CDK Completed AWS CloudFront workshop and gained expertise in:\nGlobal content delivery network configuration Origin and behavior settings optimization Cache policies and TTL configurations Edge locations and performance optimization SSL/TLS certificate management for secure delivery Implemented serverless CI/CD pipeline using AWS CodePipeline:\nCreated automated build and deployment workflows Configured source code integration with version control Acquired comprehensive knowledge of modern DevOps practices:\nInfrastructure as Code (IaC) principles and implementation Continuous Integration and Continuous Deployment (CI/CD) "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.5-cognito-function/5.5.3-protected-routes/","title":"Implement Auth Context &amp; Protected Routes","tags":[],"description":"","content":"5.5.3 Implement Auth Context \u0026amp; Protected Routes Global authentication state + automatic route protection\nYou‚Äôve built the Cognito logic and the beautiful UI.\nNow you‚Äôll connect everything with a global AuthContext and a smart ProtectedRoute ‚Äî exactly as you designed.\n1. Global Auth Context ‚Äì context/AuthContext.tsx \u0026#39;use client\u0026#39;; import { createContext, useContext, useEffect, useState } from \u0026#39;react\u0026#39;; import { getCognitoUser, cognitoSignOut } from \u0026#39;@/lib/cognito-auth\u0026#39;; interface User { userId: string; email: string; name: string; role: \u0026#39;admin\u0026#39; | \u0026#39;user\u0026#39;; } interface AuthContextType { user: User | null; loading: boolean; signOut: () =\u0026gt; Promise\u0026lt;void\u0026gt;; refreshUser: () =\u0026gt; Promise\u0026lt;void\u0026gt;; } const AuthContext = createContext\u0026lt;AuthContextType | undefined\u0026gt;(undefined); export function AuthProvider({ children }: { children: React.ReactNode }) { const [user, setUser] = useState\u0026lt;User | null\u0026gt;(null); const [loading, setLoading] = useState(true); const loadUser = async () =\u0026gt; { try { const userData = await getCognitoUser(); if (userData) { setUser({ userId: userData.userId, email: userData.email, name: userData.name, role: userData.role === \u0026#39;admin\u0026#39; ? \u0026#39;admin\u0026#39; : \u0026#39;user\u0026#39;, }); } else { setUser(null); } } catch (error) { console.error(\u0026#39;Failed to load user:\u0026#39;, error); setUser(null); } finally { setLoading(false); } }; useEffect(() =\u0026gt; { loadUser(); }, []); const signOut = async () =\u0026gt; { try { await cognitoSignOut(); setUser(null); } catch (error) { console.error(\u0026#39;Sign out error:\u0026#39;, error); } }; return ( \u0026lt;AuthContext.Provider value={{ user, loading, signOut, refreshUser: loadUser }}\u0026gt; {children} \u0026lt;/AuthContext.Provider\u0026gt; ); } export function useAuth() { const context = useContext(AuthContext); if (!context) { throw new Error(\u0026#39;useAuth must be used within an AuthProvider\u0026#39;); } return context; } 2. Protected Route Component ‚Äì components/ProtectedRoute.tsx \u0026#39;use client\u0026#39;; import { useEffect } from \u0026#39;react\u0026#39;; import { useRouter } from \u0026#39;next/navigation\u0026#39;; import { useAuth } from \u0026#39;@/context/AuthContext\u0026#39;; export function ProtectedRoute({ children }: { children: React.ReactNode }) { const { user, loading } = useAuth(); const router = useRouter(); useEffect(() =\u0026gt; { if (!loading \u0026amp;\u0026amp; !user) { router.push(\u0026#39;/signin\u0026#39;); } }, [user, loading, router]); if (loading) { return ( \u0026lt;div className=\u0026#34;min-h-screen flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;text-xl font-medium\u0026#34;\u0026gt;Loading...\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } if (!user) { return null; // Redirecting... } return \u0026lt;\u0026gt;{children}\u0026lt;/\u0026gt;; } Congratulations! You\u0026rsquo;ve built a 2025-standard, AWS-native authentication flow that top-tier teams use daily.\nNavigation:\nPrevious: 5.5.2 Build Authentication UI Next Step: 5.5.4 Project Demo ‚Üí Run and test the complete authentication system "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.5-cognito-function/5.5.4-use-project-demo/","title":"Use demo project for cognito authentication","tags":[],"description":"","content":"5.5.4 Use demo project for cognito authentication Global authentication state + automatic route protection\nI have sourecode contain the UI . So You‚Äôve built the Cognito logic\nNow you‚Äôll connect everything with a global AuthContext and a smart ProtectedRoute ‚Äî exactly as you designed.\n1. Global Auth Context ‚Äì context/AuthContext.tsx \u0026#39;use client\u0026#39;; import { createContext, useContext, useEffect, useState } from \u0026#39;react\u0026#39;; import { getCognitoUser, cognitoSignOut } from \u0026#39;@/lib/cognito-auth\u0026#39;; interface User { userId: string; email: string; name: string; role: \u0026#39;admin\u0026#39; | \u0026#39;user\u0026#39;; } interface AuthContextType { user: User | null; loading: boolean; signOut: () =\u0026gt; Promise\u0026lt;void\u0026gt;; refreshUser: () =\u0026gt; Promise\u0026lt;void\u0026gt;; } const AuthContext = createContext\u0026lt;AuthContextType | undefined\u0026gt;(undefined); export function AuthProvider({ children }: { children: React.ReactNode }) { const [user, setUser] = useState\u0026lt;User | null\u0026gt;(null); const [loading, setLoading] = useState(true); const loadUser = async () =\u0026gt; { try { const userData = await getCognitoUser(); if (userData) { setUser({ userId: userData.userId, email: userData.email, name: userData.name, role: userData.role === \u0026#39;admin\u0026#39; ? \u0026#39;admin\u0026#39; : \u0026#39;user\u0026#39;, }); } else { setUser(null); } } catch (error) { console.error(\u0026#39;Failed to load user:\u0026#39;, error); setUser(null); } finally { setLoading(false); } }; useEffect(() =\u0026gt; { loadUser(); }, []); const signOut = async () =\u0026gt; { try { await cognitoSignOut(); setUser(null); } catch (error) { console.error(\u0026#39;Sign out error:\u0026#39;, error); } }; return ( \u0026lt;AuthContext.Provider value={{ user, loading, signOut, refreshUser: loadUser }}\u0026gt; {children} \u0026lt;/AuthContext.Provider\u0026gt; ); } export function useAuth() { const context = useContext(AuthContext); if (!context) { throw new Error(\u0026#39;useAuth must be used within an AuthProvider\u0026#39;); } return context; } 2. Protected Route Component ‚Äì components/ProtectedRoute.tsx \u0026#39;use client\u0026#39;; import { useEffect } from \u0026#39;react\u0026#39;; import { useRouter } from \u0026#39;next/navigation\u0026#39;; import { useAuth } from \u0026#39;@/context/AuthContext\u0026#39;; export function ProtectedRoute({ children }: { children: React.ReactNode }) { const { user, loading } = useAuth(); const router = useRouter(); useEffect(() =\u0026gt; { if (!loading \u0026amp;\u0026amp; !user) { router.push(\u0026#39;/signin\u0026#39;); } }, [user, loading, router]); if (loading) { return ( \u0026lt;div className=\u0026#34;min-h-screen flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;text-xl font-medium\u0026#34;\u0026gt;Loading...\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } if (!user) { return null; // Redirecting... } return \u0026lt;\u0026gt;{children}\u0026lt;/\u0026gt;; } when done all thing . i have to add protected to dashboard to block people dont login to access dashboard and protected page .\njust add protected page like this\n\u0026#34;use client\u0026#34; import { ProtectedRoute } from \u0026#34;@/components/ProtectedRoute\u0026#34; import { useAuth } from \u0026#34;@/context/AuthContext\u0026#34; import { LogOut, User, Mail, Shield, KeyRound, ArrowRight } from \u0026#34;lucide-react\u0026#34; import Link from \u0026#34;next/link\u0026#34; export default function DashboardPage() { const { user, signOut } = useAuth() const handleSignOut = async () =\u0026gt; { await signOut() } return ( \u0026lt;ProtectedRoute\u0026gt; \u0026lt;div className=\u0026#34;min-h-screen bg-gradient-to-br from-background via-background to-secondary/5\u0026#34;\u0026gt; {/* Header */} \u0026lt;header className=\u0026#34;border-b border-border/50 backdrop-blur-sm sticky top-0 z-50\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;max-w-6xl mx-auto px-6 py-4 flex items-center justify-between\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex items-center gap-3\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-10 h-10 rounded-lg bg-gradient-to-br from-primary to-primary/60 flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;User className=\u0026#34;w-6 h-6 text-primary-foreground\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h1 className=\u0026#34;text-xl font-bold text-foreground\u0026#34;\u0026gt;Dashboard\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button onClick={handleSignOut} className=\u0026#34;inline-flex items-center gap-2 px-4 py-2 rounded-lg text-sm font-medium bg-destructive/10 text-destructive hover:bg-destructive/20 transition-colors\u0026#34; \u0026gt; \u0026lt;LogOut className=\u0026#34;w-4 h-4\u0026#34; /\u0026gt; Sign Out \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/header\u0026gt; {/* Main Content */} \u0026lt;main className=\u0026#34;max-w-6xl mx-auto px-6 py-12\u0026#34;\u0026gt; {/* Welcome Section */} \u0026lt;div className=\u0026#34;mb-12\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;space-y-2 mb-8\u0026#34;\u0026gt; \u0026lt;h2 className=\u0026#34;text-4xl font-bold text-foreground\u0026#34;\u0026gt;Welcome back\u0026lt;/h2\u0026gt; \u0026lt;p className=\u0026#34;text-lg text-muted-foreground\u0026#34;\u0026gt;{user?.name || user?.email}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; {/* Stats Cards */} \u0026lt;div className=\u0026#34;grid grid-cols-1 md:grid-cols-3 gap-6\u0026#34;\u0026gt; {/* Profile Status Card */} \u0026lt;div className=\u0026#34;group relative overflow-hidden rounded-2xl bg-card border border-border/50 p-6 hover:shadow-lg transition-shadow duration-300\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;absolute inset-0 bg-gradient-to-br from-primary/5 to-transparent opacity-0 group-hover:opacity-100 transition-opacity\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;relative space-y-4\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-12 h-12 rounded-xl bg-primary/10 flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;Shield className=\u0026#34;w-6 h-6 text-primary\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3 className=\u0026#34;text-sm font-semibold text-muted-foreground uppercase tracking-wide\u0026#34;\u0026gt; Account Status \u0026lt;/h3\u0026gt; \u0026lt;p className=\u0026#34;text-2xl font-bold text-foreground mt-2\u0026#34;\u0026gt;Active\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/* Role Card */} \u0026lt;div className=\u0026#34;group relative overflow-hidden rounded-2xl bg-card border border-border/50 p-6 hover:shadow-lg transition-shadow duration-300\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;absolute inset-0 bg-gradient-to-br from-accent/5 to-transparent opacity-0 group-hover:opacity-100 transition-opacity\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;relative space-y-4\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-12 h-12 rounded-xl bg-accent/10 flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;User className=\u0026#34;w-6 h-6 text-accent\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3 className=\u0026#34;text-sm font-semibold text-muted-foreground uppercase tracking-wide\u0026#34;\u0026gt;User Role\u0026lt;/h3\u0026gt; \u0026lt;p className=\u0026#34;text-2xl font-bold text-foreground mt-2 capitalize\u0026#34;\u0026gt;{user?.role || \u0026#34;Member\u0026#34;}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/* Verification Status */} \u0026lt;div className=\u0026#34;group relative overflow-hidden rounded-2xl bg-card border border-border/50 p-6 hover:shadow-lg transition-shadow duration-300\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;absolute inset-0 bg-gradient-to-br from-chart-1/5 to-transparent opacity-0 group-hover:opacity-100 transition-opacity\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;relative space-y-4\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-12 h-12 rounded-xl bg-chart-1/10 flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;Mail className=\u0026#34;w-6 h-6 text-chart-1\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3 className=\u0026#34;text-sm font-semibold text-muted-foreground uppercase tracking-wide\u0026#34;\u0026gt; Email Status \u0026lt;/h3\u0026gt; \u0026lt;p className=\u0026#34;text-2xl font-bold text-foreground mt-2\u0026#34;\u0026gt;Verified\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/* User Information Section */} \u0026lt;div className=\u0026#34;grid grid-cols-1 lg:grid-cols-3 gap-6\u0026#34;\u0026gt; {/* Main User Card */} \u0026lt;div className=\u0026#34;lg:col-span-2 rounded-2xl bg-card border border-border/50 overflow-hidden hover:shadow-lg transition-shadow duration-300\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;h-24 bg-gradient-to-r from-primary to-accent/50\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;p-8 -mt-12 relative\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;mb-8\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-24 h-24 rounded-2xl bg-card border-4 border-background shadow-lg flex items-center justify-center mb-6\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;w-full h-full bg-gradient-to-br from-primary/20 to-accent/20 rounded-xl flex items-center justify-center\u0026#34;\u0026gt; \u0026lt;User className=\u0026#34;w-12 h-12 text-primary\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h3 className=\u0026#34;text-2xl font-bold text-foreground\u0026#34;\u0026gt;{user?.name || user?.email}\u0026lt;/h3\u0026gt; \u0026lt;p className=\u0026#34;text-muted-foreground mt-1\u0026#34;\u0026gt;Authenticated User\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;space-y-4 pt-8 border-t border-border/50\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex items-start gap-4\u0026#34;\u0026gt; \u0026lt;Mail className=\u0026#34;w-5 h-5 text-primary mt-1 flex-shrink-0\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;flex-1 min-w-0\u0026#34;\u0026gt; \u0026lt;p className=\u0026#34;text-sm text-muted-foreground\u0026#34;\u0026gt;Email Address\u0026lt;/p\u0026gt; \u0026lt;p className=\u0026#34;text-foreground font-medium break-all\u0026#34;\u0026gt;{user?.email}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;flex items-start gap-4\u0026#34;\u0026gt; \u0026lt;Shield className=\u0026#34;w-5 h-5 text-accent mt-1 flex-shrink-0\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;flex-1\u0026#34;\u0026gt; \u0026lt;p className=\u0026#34;text-sm text-muted-foreground\u0026#34;\u0026gt;User ID\u0026lt;/p\u0026gt; \u0026lt;p className=\u0026#34;text-foreground font-medium font-mono text-sm\u0026#34;\u0026gt;{user?.userId || \u0026#34;N/A\u0026#34;}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;flex items-start gap-4\u0026#34;\u0026gt; \u0026lt;User className=\u0026#34;w-5 h-5 text-chart-1 mt-1 flex-shrink-0\u0026#34; /\u0026gt; \u0026lt;div className=\u0026#34;flex-1\u0026#34;\u0026gt; \u0026lt;p className=\u0026#34;text-sm text-muted-foreground\u0026#34;\u0026gt;Account Role\u0026lt;/p\u0026gt; \u0026lt;p className=\u0026#34;text-foreground font-medium capitalize\u0026#34;\u0026gt;{user?.role || \u0026#34;Member\u0026#34;}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/* Actions Sidebar */} \u0026lt;div className=\u0026#34;space-y-4\u0026#34;\u0026gt; \u0026lt;Link href=\u0026#34;/forgot-password\u0026#34; className=\u0026#34;flex items-center justify-between gap-3 p-4 rounded-xl bg-card border border-border/50 hover:bg-secondary/50 hover:border-border transition-all duration-200 group\u0026#34; \u0026gt; \u0026lt;div className=\u0026#34;flex items-center gap-3\u0026#34;\u0026gt; \u0026lt;KeyRound className=\u0026#34;w-5 h-5 text-primary\u0026#34; /\u0026gt; \u0026lt;span className=\u0026#34;font-medium text-foreground\u0026#34;\u0026gt;Change Password\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;ArrowRight className=\u0026#34;w-4 h-4 text-muted-foreground group-hover:translate-x-1 transition-transform\u0026#34; /\u0026gt; \u0026lt;/Link\u0026gt; \u0026lt;button onClick={handleSignOut} className=\u0026#34;w-full flex items-center justify-between gap-3 p-4 rounded-xl bg-destructive/10 border border-destructive/20 hover:bg-destructive/20 transition-all duration-200 group\u0026#34; \u0026gt; \u0026lt;div className=\u0026#34;flex items-center gap-3\u0026#34;\u0026gt; \u0026lt;LogOut className=\u0026#34;w-5 h-5 text-destructive\u0026#34; /\u0026gt; \u0026lt;span className=\u0026#34;font-medium text-destructive\u0026#34;\u0026gt;Sign Out\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;ArrowRight className=\u0026#34;w-4 h-4 text-destructive/50 group-hover:translate-x-1 transition-transform\u0026#34; /\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/ProtectedRoute\u0026gt; ) } Congratulations! You\u0026rsquo;ve built a 2025-standard, AWS-native authentication flow that top-tier teams use daily.\nNavigation:\nPrevious: 5.5.3 Implement Protected Routes Next Step: 5.6 Testing \u0026amp; Verification ‚Üí Run and verify the complete authentication system "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.3-aws-cognito/","title":"AWS Cognito Setup","tags":[],"description":"","content":"AWS Cognito Setup In this section, you will set up Amazon Cognito User Pool and configure essential settings such as login options, password policies, and app client settings.\nThis configuration will be used later in the Next.js project through the Amplify SDK.\nContent Create a Cognito User Pool Configure App Client Navigation:\nPrevious: 5.2 Prerequisites Next Step: 5.3.1 Next.js Project Setup ‚Üí Create Cognito "},{"uri":"https://thormastran.github.io/fcj-workshop-template/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nSummary Report: ‚ÄúAWS DevOps Day ‚Äì From CI/CD to Observability‚Äù Event Objectives Master the complete modern AWS DevOps stack in one intensive day Understand end-to-end CI/CD, Infrastructure as Code, Containers, and Observability Hands-on experience through multiple live demos Learn real-world best practices and transformation case studies Speakers AWS Senior Solutions Architects (DevOps \u0026amp; Containers) AWS Developer Advocates DevOps engineering Tymex Key Highlights DevOps Culture \u0026amp; Core Metrics Strong focus on DORA metrics: Deployment Frequency, Lead Time for Changes, MTTR, Change Failure Rate Shift from ‚ÄúDevOps team‚Äù ‚Üí DevOps culture across the entire organization Full AWS CI/CD Pipeline (CodeSuite) Source: CodeCommit + Trunk-based development (moving away from GitFlow) Build \u0026amp; Test: CodeBuild with parallel testing and caching Deploy: CodeDeploy supporting Blue/Green, Canary, and Linear rollouts Orchestration: CodePipeline with manual approval gates Live demo: Zero-downtime deployment pipeline built from scratch in \u0026lt;20 minutes Infrastructure as Code ‚Äì CloudFormation vs CDK CloudFormation: reliable, mature, drift detection AWS CDK: developer-friendly (TypeScript/Python/Java/C#), reusable constructs, faster iteration Clear decision framework: use CDK for new projects, CloudFormation for regulated environments Live demo: same VPC + ECS service deployed with both tools side-by-side Container Ecosystem on AWS ECR: vulnerability scanning + image signing ECS Fargate vs EKS: when to choose serverless containers vs full Kubernetes AWS App Runner: the fastest way to production for simple web apps Case study comparison: startup (App Runner) vs enterprise finance (EKS) Observability Triad CloudWatch: metrics, logs, alarms, Container Insights, Lambda Insights X-Ray: distributed tracing across Lambda, ECS, API Gateway Live demo: full observability stack set up in 10 minutes with automated dashboards Advanced DevOps Practices Feature flags + dark launches Chaos engineering introduction Blameless postmortems culture Real customer stories: 1 startup went from 1 deploy/month ‚Üí 50 deploys/day; 1 bank reduced MTTR from 4 hours ‚Üí \u0026lt;15 minutes Key Takeaways Trunk-based development + short-lived branches is the fastest path to high DORA performance AWS CDK has become the default choice for 90% of new projects at AWS customers You no longer need to choose between ‚Äúsimple‚Äù and ‚Äúpowerful‚Äù ‚Äî App Runner ‚Üí ECS ‚Üí EKS is a smooth progression path Observability must be designed Day 1, not added later Zero-downtime deployments are now table stakes, not nice-to-have Applying to Work (30-60-90 Day Plan) 30 days: migrate at least 1 repo to Trunk-based + enable CodeBuild caching 60 days: convert 1 existing CloudFormation template to CDK (or start new project with CDK) 90 days: implement Blue/Green or Canary deployment for 1 critical service + full CloudWatch/X-Ray observability Long-term: target Elite DORA performer status in 2026 Event Experience One of the most intense and value-packed workshops I‚Äôve ever attended ‚Äî full day from 8:30 AM to 5:00 PM, yet time flew by because every minute was either live demo or real-world discussion. The demos were 100% reproducible (speaker shared GitHub repo immediately). The case-study session with Vietnamese companies was particularly inspiring ‚Äî proved that local teams can achieve world-class DevOps maturity.\n‚ÄúThis wasn‚Äôt a slideware workshop ‚Äî we built and deployed production-grade pipelines, IaC, containers, and observability in real time.‚Äù\nHands down the best AWS DevOps learning experience in 2025 so far.\nEvent photos\n(Add photos: group photo, live demo screenshots, white-boarding sessions, networking, etc.)\nHighly recommend this format to any team serious about modern cloud development!\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nThis section will list and introduce the blogs you have translated. For example:\nBlog 1 - AWS gears up for action-packed Gamescom and Devcom 2024 Gamescom is one of a few opportunities each year where the global gaming and game development community get to converge, immerse themselves in the latest gaming experiences, and interact with industry game changers. We can‚Äôt wait to see what‚Äôs in store this year.\nBlog 2 - Best practices for utilizing AWS Systems Manager with AWS Fault Injection Service In this blog post, we‚Äôll explore best practices for using SSM with FIS. We‚Äôll delve into how this powerful duo can be leveraged to create more comprehensive and realistic chaos engineering experiments, going beyond the standard FIS actions to simulate a wider range of failure scenarios.\nBlog 3 - Effective cost optimization strategies for Amazon Bedrock Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, DeepSeek, Luma, Meta, Mistral AI, Stability AI, and Amazon through a single API, along with a broad set of capabilities you need to build generative AI applications with security, privacy, and responsible AI. Using Amazon Bedrock, you can experiment with and evaluate top FMs for your use case, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources.\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report.\nSummary Report: ‚ÄúAWS Security Day ‚Äì 5 Security Pillars in Practice‚Äù Event Objectives Deep understanding of the 5 AWS Security Pillar areas Learn production-grade patterns used by top Vietnamese enterprises and financial institutions Walk away with immediately actionable security improvements Speakers AWS Senior Security Solutions Architect AWS Vietnam Security Specialist Team Guest speaker from a local bank that achieved 100% Security Pillar compliance Key Highlights 1. Identity \u0026amp; Access Management (IAM) ‚Äì Modern Approach Zero long-term credentials in code ‚Äî always use roles and temporary credentials IAM Identity Center + Permission Sets as the new default (replacing IAM Users) Service Control Policies (SCPs) + Permission Boundaries mandatory for multi-account environments Mini demo: IAM Access Analyzer found overly permissive policies in \u0026lt;30 seconds 2. Detection \u0026amp; Continuous Monitoring Mandatory trio: Organization-level CloudTrail + GuardDuty + Security Hub Enable VPC Flow Logs, S3 Server Access Logging, ALB logs everywhere Detection-as-Code: custom GuardDuty rules via Terraform Real Vietnam story: GuardDuty caught crypto-mining on EC2 on Day 1 3. Infrastructure Protection VPC design principle: nothing public unless absolutely required Security Groups = allow rules, NACLs = final deny layer WAF + Shield Advanced now table stakes for any customer-facing application in Vietnam 4. Data Protection Customer-managed KMS keys with automatic rotation as default S3: Block Public Access + default SSE-KMS enforced at organization level Secrets Manager + automatic 90-day credential rotation pattern Data classification framework: Public ‚Üí Internal ‚Üí Sensitive ‚Üí Restricted 5. Incident Response (IR) ‚Äì Ready-to-Use Playbooks Top 3 incidents in Vietnam: Compromised IAM keys Public S3 buckets Crypto-mining on EC2 Standard IR flow: Isolate ‚Üí Snapshot ‚Üí Investigate ‚Üí Remediate Live demo: automated remediation with Lambda + EventBridge (auto-detach malicious IAM policy when GuardDuty fires) Key Takeaways 90% of breaches in Vietnam start with weak IAM or missing MFA Turning on GuardDuty + Security Hub instantly reveals existing critical issues Multi-account strategy + Landing Zone + Control Tower is the only scalable secure model Security is not a one-time project ‚Äî it‚Äôs a continuous discipline Vietnamese companies can (and must) achieve world-class cloud security today "},{"uri":"https://thormastran.github.io/fcj-workshop-template/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim for your report, including this warning.\nIn this section, you should list and describe in detail the events you have participated in during your internship or work experience.\nEach event should be presented in the format Event 1, Event 2, Event 3‚Ä¶, along with the following details:\nEvent name Date and time Location (if applicable) Your role in the event (attendee, event support, speaker, etc.) A brief description of the event‚Äôs content and main activities Outcomes or value gained (lessons learned, new skills, contribution to the team/project) This listing helps demonstrate your actual participation as well as the soft skills and experience you have gained from each event. During my internship, I participated in two events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: AWS Cloud Day Vietnam - AI Edition 2025\nDate \u0026amp; Time: 09:00, September 18, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: AWS Cloud Mastery Series #1\nDate \u0026amp; Time: 08:30, November 15, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: AWS Cloud Mastery Series #2\nDate \u0026amp; Time: 08:30, November 15, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 4 Event Name: AWS Cloud Mastery Series #3\nDate \u0026amp; Time: 08:30, November 15, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 5 Event Name: AWS Cloud Update Q4 ‚Äì 2025\nDate \u0026amp; Time: 10:00, November 6, 2025\nLocation: online on Teams Role: Attendee\nEvent 6 Event Name: AI, Data Interview ( Nguy·ªÖn Gia H∆∞ng (Head of SA, AWS))\nDate \u0026amp; Time: 10:00, October 17, 2025\nLocation: online on Youtube Role: Attendee\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.4-next.js-setup/","title":"Next.js Project Setup &amp; Amplify Configuration","tags":[],"description":"","content":"Next.js Project Setup \u0026amp; Amplify Configuration In this section, you will set up a Next.js application, install the required Amplify SDK packages, and configure Amplify to connect your web application to the Cognito User Pool created earlier.\nYou will prepare the base environment that will be used later to build authentication features such as sign-up, sign-in, sign-out, and protected routes.\nContent Install Next.js Project Install Amplify SDK and Configure Navigation:\nPrevious: 5.3 AWS Cognito Setup Next Step: 5.5 Authentication Functions ‚Üí Build auth functions, UI, and protected routes "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.5-cognito-function/","title":"Authentication Functions, UI, and Protected Routes","tags":[],"description":"","content":"Authentication Functions, UI, and Protected Routes In this section, you will integrate AWS Cognito into your Next.js application using the Amplify SDK.\nYou will implement core authentication logic, build a user-friendly UI, and secure specific pages using protected routes.\nBy the end of this section, your application will support:\n‚úî Features You Will Implement Sign Up Function\nCreate new users in Cognito (with email verification).\nSign In Function\nAuthenticate users and receive Cognito-issued tokens.\nSign Out Function\nProperly terminate the authenticated session through Amplify.\nSession Handling\nCheck whether users are logged in and retrieve current session info.\nProtected Routes\nRestrict access to certain pages unless the user is authenticated.\nUI Components\nBuild simple authentication pages such as Login, Register, Profile, and Dashboard using your chosen UI library.\nQuick options\nYou can either use the live demo for a fast setup or follow the step‚Äëby‚Äëstep guides below to edit functions and UI directly.\nYou can either use the live demo for a fast setup or follow the step‚Äëby‚Äëstep guides below:\nCreate Cognito Authentication Functions Build Authentication UI Implement Auth Context \u0026amp; Protected Routes Use Project Demo (Quick Start) Quick Start Demo: https://github.com/Thormastran/my-cognito-project/\nNavigation:\nPrevious: 5.4 Next.js Project Setup Next Step: 5.6 Full Testing \u0026amp; Verification ‚Üí Test all authentication features follow the guides for detailed customization and explanation. Content Create Cognito Authentication Functions Build Authentication UI Implement Auth Context \u0026amp; Protected Routes 4.Full Testing \u0026amp; Verification "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/","title":"AWS Cognito with Amplify SDK Workshop","tags":[],"description":"","content":" Warning: The content below is for training and reference purposes only. Please do not copy verbatim into official reports or public documentation.\nAWS Cognito + Amplify SDK Workshop Overview Amazon Cognito is a fully managed user authentication, authorization, and user management service that makes it easy to add sign-up, sign-in, and access control to web and mobile apps.\nIn this hands-on workshop, you will:\nCreate and configure a Cognito User Pool from scratch Integrate the latest AWS Amplify Gen 2 (v6+) with Next.js 14 (App Router) Implement a complete authentication flow:\nSign-up ‚Üí Email verification ‚Üí Sign-in ‚Üí Protected routes ‚Üí Role-based access Follow production-ready best practices (SSR support, secure token handling, clean architecture) Final outcome: A fully functional, secure Next.js application with user authentication ‚Äî ready to deploy on Vercel, Netlify, or AWS Amplify Hosting.\nWorkshop Contents Workshop Overview\nWhat are Amazon Cognito and AWS Amplify? Why use them together? Prerequisites\nAWS account, IAM user, AWS CLI Node.js 18+, npm, VS Code AWS Cognito Setup\nCreate User Pool with email sign-in Configure password policy, optional MFA, App Client (no client secret) Create Cognito Groups (admin / user) Next.js Project Setup \u0026amp; Amplify Configuration\nScaffold Next.js 14 with App Router + TypeScript + Tailwind CSS Install aws-amplify@latest Configure environment variables and Amplify SSR mode Authentication Functions, UI, and Protected Routes\nComplete Cognito helpers: signUp, confirmSignUp, signIn, signOut, getCurrentUser, etc. Global AuthContext + custom useAuth hook Sign-up, email verification, sign-in, and forgot password pages ProtectedRoute component Dashboard page displaying user info and role Full Testing \u0026amp; Verification\nEnd-to-end test checklist Common errors and troubleshooting tips Clean Up Resources\nDelete User Pool and App Client to avoid unwanted charges Estimated duration: 3‚Äì4 hours\nDifficulty: Intermediate (basic React/Next.js knowledge recommended)\nLet‚Äôs get started! ‚Üí Click on 5.1 Workshop Overview to begin.\nHappy authenticating!\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nSummary Report: ‚ÄúAWS Cloud Update Q4 ‚Äì 2025‚Äù Event Objectives Review the most important AWS launches and announcements from Q3 2025 Reveal upcoming features, roadmap highlights for Q4 2025 and 2026 Understand how the latest AI, compute, security, and cost-optimization innovations impact enterprise digital transformation Provide actionable insights and direct Q\u0026amp;A with AWS Solution Architects Speakers AWS Senior Solutions Architects (DevOps \u0026amp; Containers) AWS Developer Advocates DevOps engineering Tymex Key Highlights AWS Financial Performance \u0026amp; Investment Momentum (Q3 2025) AWS revenue reached $33 billion (+20.2% YoY) ‚Äî fastest growth since 2022 Operating margin improved to 32.9% Amazon announced $125 billion CapEx for 2025, with the majority allocated to AWS AI infrastructure New 3.8 GW of power capacity added in the last 12 months; plan to double total capacity by 2027\nMajor Infrastructure \u0026amp; AI Announcements Trainium3 UltraServers ‚Äì 4.4√ó higher training performance and 4√ó better energy efficiency than Trainium2 Graviton5 ‚Äì highest price-performance ARM-based instance yet launched Project Rainier ‚Äì massive Trainium2 cluster already in production for Anthropic and other foundation-model customers Amazon Bedrock \u0026amp; SageMaker updates ‚Äì serverless custom model training, reinforcement fine-tuning, and new ‚ÄúFrontier Agents‚Äù framework\nAI Agents \u0026amp; Autonomous Systems Introduction of ‚ÄúFrontier Agents‚Äù ‚Äì next-generation autonomous AI agents that can work continuously for days without human intervention New Bedrock AgentCore ‚Äì fully managed runtime for multi-agent systems Live demo: building a multi-step procurement agent that negotiates with vendors, creates POs, and updates ERP systems end-to-end\nSecurity \u0026amp; Governance Enhancements Default encryption for all new VPC traffic IAM Access Analyzer ‚Äì new policy validation at scale GuardDuty EKS Runtime Monitoring now GA\nCost Optimization \u0026amp; Sustainability Up to 40% lower inference cost with Trainium3 Graviton5 delivers ~20% better price-performance than Graviton4 New Carbon Footprint Tool with hourly granularity\nVietnam Market Insights (True IDC session) Case studies: Vietnamese e-commerce reduced inference cost 52% after migrating to Trainium Banking customer achieved zero-downtime migration of 300+ workloads using AWS Migration Hub + Graviton Special 3-month unlimited AWS credit offer exclusive for webinar attendees\nKey Takeaways AI infrastructure is now the primary growth driver for AWS ‚Äì expect continued massive CapEx in 2026‚Äì2027 Frontier Agents and multi-agent systems are moving from research to production-ready in 2026 For most workloads, Graviton5 + Trainium3 is now the default cost-performance choice Serverless custom model training removes the last barrier for enterprises to build their own foundation models Zero-trust and default encryption are becoming non-negotiable table stakes\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.6-testing/","title":"Full Testing &amp; Verification","tags":[],"description":"","content":"5.6 Full Testing \u0026amp; Verification Your app is ready ‚Äî let‚Äôs prove it works perfectly\n1. Start the Application npm run dev Open ‚Üí http://localhost:3000\n2 Full Testing \u0026amp; Verification ‚Äì Checklist (Tick as you go!) Done # Action Expected Result ‚òê 1 Open homepage (/) Welcome card with Login and Sign Up buttons ‚òê 2 Click Sign Up ‚Üí go to /signup Clean sign-up form appears ‚òê 3 Register with new email + strong password Success ‚Üí switches to \u0026ldquo;Verify Email\u0026rdquo; screen ‚òê 4 Check your email (including Spam/Promotions) Receive 6-digit verification code from Amazon Cognito ‚òê 5 Enter the code Success ‚Üí automatically redirected to Sign In page ‚òê 6 Sign in with the same credentials Success ‚Üí redirected to Dashboard ‚òê 7 Dashboard loads Shows your name, email, role = user, and beautiful layout ‚òê 8 Click Sign Out Logged out ‚Üí back to homepage ‚òê 9 Open new tab ‚Üí go directly to /dashboard Immediately redirected to /signin ‚Üí ProtectedRoute works perfectly ‚òê 10 Try signing up with the same email again Error: ‚ÄúAccount already exists.‚Äù ‚òê 11 Sign in with wrong password Error: ‚ÄúInvalid email or password‚Äù ‚òê 12 Create new user ‚Üí don\u0026rsquo;t verify ‚Üí try login Error: \u0026ldquo;Please verify your email first\u0026rdquo; 3. Change Password Testing Done # Action Expected Result ‚òê 13 Sign in with verified account Successfully logged in to Dashboard ‚òê 14 Navigate to Change Password section Form with Current Password, New Password, Confirm New Password fields ‚òê 15 Submit with wrong current password Error: \u0026ldquo;Current password is incorrect\u0026rdquo; ‚òê 16 Submit with weak new password Error: \u0026ldquo;Password does not meet requirements\u0026rdquo; ‚òê 17 Submit with mismatched confirm password Error: \u0026ldquo;Passwords do not match\u0026rdquo; ‚òê 18 Submit with correct current + strong new password Success: \u0026ldquo;Password changed successfully\u0026rdquo; ‚òê 19 Sign out and sign in with old password Error: \u0026ldquo;Invalid email or password\u0026rdquo; ‚òê 20 Sign in with new password Success ‚Üí Dashboard loads correctly 4. Forgot Password Testing Done # Action Expected Result ‚òê 21 Go to Sign In page ‚Üí Click Forgot Password? Redirected to Forgot Password page ‚òê 22 Enter registered email address Success: \u0026ldquo;Reset code sent to your email\u0026rdquo; ‚òê 23 Check email for password reset code Receive 6-digit reset code from Amazon Cognito ‚òê 24 Enter reset code + new strong password Success: \u0026ldquo;Password reset successfully\u0026rdquo; ‚Üí redirected to Sign In ‚òê 25 Sign in with new password Success ‚Üí Dashboard loads correctly All 25 checks passed? ‚Üí You\u0026rsquo;ve just built a 100% working, production-grade authentication system with complete password management!\nwhen you access dashboard like this picture . You\u0026rsquo;re officially done ‚Äî go deploy it and show the world!\nNavigation:\nPrevious: 5.5 Authentication Functions Next Step: 5.7 Clean Up Resources ‚Üí Remove AWS resources to avoid charges Next ‚Üí 5.7 Clean Up Resources (optional but recommended)\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/4-eventparticipated/4.6-event6/","title":"Event 6","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nSummary Report: \u0026ldquo;GenAI ‚Äì Journey from Traditional AI Engineer to Practical GenAI Engineer\u0026rdquo; 1. Participation Objectives Understand trends in Generative AI (GenAI) application in enterprises 2025‚Äì2026 Learn the differences between traditional AI Engineers and GenAI Engineers Build a skill development roadmap aligned with market demands 2. Main Content 2.1. Comparison between Traditional AI Engineer and GenAI Engineer Criteria Traditional AI Engineer GenAI Engineer (2025) Work Objectives Build ML models from scratch Integrate GenAI into enterprise applications Core Skills Math, Statistics, Python, R, ML algorithms Prompt Engineering, Fine-tuning, Software Engineering Main Tools TensorFlow, PyTorch, Spark LLM APIs (GPT, Claude), LangChain, Vector DB Practical Applications Long-term research Quick solutions: chatbots, inventory checks, automation Note: GenAI Engineer requires strong Software Engineering skills (70%) combined with AI knowledge (30%), focusing on production deployment with low cost, optimal latency, and data security.\n2.2. GenAI Role in IT Software Developer: Accelerate coding by 30‚Äì50% with AI coding assistants Cloud Engineer: Automate debugging, log analysis, Infrastructure-as-Code writing Enterprise: Apply GenAI to real problems like shelf checking, internal chatbots, report summarization 2.3. Common Misconceptions about GenAI Prompt Engineering is simple: Reality requires understanding Context Window, Chain-of-Thought, Few-shot to create stable output GenAI replaces coders: Wrong, coders who know how to use GenAI will replace those who don\u0026rsquo;t Just calling APIs is enough: Production requires optimizing latency, cost, and security (RAG, caching, quantization) 2.4. First Cloud Journey Introduction Founded: 2020 (5 years) Achievements: Trained \u0026gt;5,000 students, helped ~200 people find jobs (mainly Cloud \u0026amp; GenAI) Mission: Develop Vietnamese technical leaders, contribute to the community 3. Value Gained Clear understanding that GenAI is mandatory for enterprise projects 2025‚Äì2026 Identified key skills: Software Engineering + Prompt Engineering + Production optimization Received learning roadmap from First Cloud Journey to become a practical GenAI Engineer in 6‚Äì12 months 4. Action Plan (Q1‚ÄìQ2/2026) Improve backend skills (FastAPI, Docker, PostgreSQL) Master Prompt Engineering and Retrieval-Augmented Generation (RAG) Build 1‚Äì2 practical GenAI projects (internal chatbot or process automation) Learn Fine-tuning (LoRA/QLoRA) and production optimization (vLLM, caching) 5. Company Recommendations Consider integrating GenAI into internal processes (e.g., HR support chatbot, report automation) Train IT team on Prompt Engineering and RAG to increase efficiency Leverage internal data to build custom GenAI solutions while ensuring security "},{"uri":"https://thormastran.github.io/fcj-workshop-template/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nDuring my internship at [AWS] from [09/08/2025] to [12/08/2025], I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI participated in [AWS company], through which I improved my skills in [list skills: programming, analysis, reporting, communication, code, AWS service].\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ‚òê ‚úÖ ‚òê 2 Ability to learn Ability to absorb new knowledge and learn quickly ‚òê ‚òê ‚úÖ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ‚úÖ ‚òê ‚òê 4 Sense of responsibility Completing tasks on time and ensuring quality ‚úÖ ‚òê ‚òê 5 Discipline Adhering to schedules, rules, and work processes ‚úÖ ‚òê ‚òê 6 Progressive mindset Willingness to receive feedback and improve oneself ‚òê ‚úÖ ‚òê 7 Communication Presenting ideas and reporting work clearly ‚úÖ ‚òê ‚òê 8 Teamwork Working effectively with colleagues and participating in teams ‚úÖ ‚òê ‚òê 9 Professional conduct Respecting colleagues, partners, and the work environment ‚úÖ ‚òê ‚òê 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ‚òê ‚úÖ ‚òê 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ‚úÖ ‚òê ‚òê 12 Overall General evaluation of the entire internship period ‚úÖ ‚òê ‚òê Needs Improvement Further develop problem-solving skills and analytical thinking. Enhance communication skills in both day-to-day interactions and professional settings, including the ability to handle situations effectively and tactfully. Further deepen knowledge and understanding of AWS services. Increase hands-on experience by completing more AWS labs and practical exercises. "},{"uri":"https://thormastran.github.io/fcj-workshop-template/5-workshop/5.7-cleanup/","title":"Clean Up Resources","tags":[],"description":"","content":"5.7 Clean Up Resources Delete everything to avoid any charges (even tiny ones)\nYou‚Äôve successfully completed the workshop ‚Äî congratulations!\nNow let‚Äôs make sure your AWS account stays $0.00.\nResources You Created (and Must Delete) Resource Location Cost if Left Running Must Delete? Cognito User Pool AWS Console ‚Üí Amazon Cognito Free tier: 50,000 MAU ‚Üí still $0 Recommended App Client (inside pool) Inside the User Pool No extra cost Auto-deleted Cognito Groups (admin/user) Inside the User Pool No cost Auto-deleted Test users (you signed up) Inside the User Pool ‚Üí Users No cost Optional Important: Amazon Cognito User Pools are free for up to 50,000 monthly active users.\nYou will never be charged for this workshop ‚Äî but it‚Äôs still best practice to clean up.\nStep-by-Step Cleanup (Takes 60 Seconds) Go to the AWS Console ‚Üí Amazon Cognito\n‚Üí ‚Å¶https://console.aws.amazon.com/cognito/home‚Å©\nSelect your region (the one you used, e.g., us-east-1)\nYou‚Äôll see your User Pool (probably named something like my-cognito-app-pool or the default name)\nClick on your User Pool ‚Üí Delete user pool (top-right button)\nType delete in the confirmation box Click Delete user pool\nDone! Everything is permanently deleted.\nOptional: Also Delete Test Users (if you want a completely clean slate) ‚Ä¢ Inside the User Pool ‚Üí Users tab ‚Üí select any test accounts ‚Üí Delete\nYou‚Äôre All Set!\nYour AWS account is now clean and back to $0.00.\nFinal Summary ‚Äì What You‚Äôve Accomplished You have built a 2025-standard, production-ready authentication system using:\n‚Ä¢ Amazon Cognito (fully managed identity) ‚Ä¢ AWS Amplify Gen 2 (v6+) ‚Äì the correct, modern, SSR-safe way ‚Ä¢ Next.js 14 App Router + React Server Components ‚Ä¢ Role-based access control via Cognito Groups ‚Ä¢ Protected routes \u0026amp; global auth context ‚Ä¢ Beautiful, accessible UI with shadcn/ui + Tailwind\nThis is exactly how professional teams at startups, enterprises, and AWS Partners build authentication today.\nYou now have a complete, deployable, real-world project you can: ‚Ä¢ Add to your portfolio ‚Ä¢ Use as a starter template ‚Ä¢ Deploy instantly to Vercel/Netlify ‚Ä¢ Show in job interviews\nYou absolutely crushed this workshop.\nNow go deploy it, share it, and be proud ‚Äî you\u0026rsquo;ve earned it!\nNavigation:\nPrevious: 5.6 Full Testing \u0026amp; Verification Workshop Complete! üéâ Return to Workshop Overview or Main Index End of Workshop\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nHere, you can freely share your personal opinions about your experience participating in the First Cloud Journey program. This will help the FCJ team improve any shortcomings based on the following aspects:\nOverall Evaluation 1. Working Environment\nThe workplace at FCJ is friendly and supportive. Colleagues are always ready to help, even outside normal working hours, which creates a great sense of teamwork. The office is tidy, well-organized, and comfortable, making it easy to stay productive. A small suggestion would be to organize more team-building or social events to help everyone bond even better.\n2. Support from Mentor / Team Admin\nMy mentor provided clear and detailed guidance while encouraging me to think independently and only stepping in when truly needed. The administrative team was highly efficient with documentation, shared all necessary resources promptly, and made the entire onboarding and daily process seamless.\n3. Relevance of Work to Academic Major\nThe tasks I was given aligned very well with my field of study, reinforcing the theory I learned in university while introducing fresh, real-world applications and new concepts I hadn‚Äôt encountered in class.\n4. Learning \u0026amp; Skill Development Opportunities\nI gained practical skills in areas such as project management tools, effective teamwork, and professional communication. My mentor also offered valuable career advice and real-industry insights that helped me better understand my long-term professional goals.\n5. Company Culture \u0026amp; Team Spirit\nThe culture is respectful, positive, and nicely balanced between professionalism and approachability. During high-pressure periods, everyone works together collaboratively regardless of position, which made me feel fully part of the team despite being an intern.\n6. Internship Policies / Benefits\nThe program offers a monthly stipend, flexible working hours when needed, and access to internal training sessions, all of which add significant value to the experience.\nAdditional Questions What was the most fulfilling part of your internship experience?\nThe most rewarding aspect was seeing how the theoretical knowledge from my studies directly applied to real projects, combined with the strong support and trust the team placed in me.\nWhich aspects do you think the company could improve for future interns?\nAdding more social or team-building activities would help new interns integrate faster and build stronger relationships with the team.\nIf a friend asked, would you recommend this place for an internship? Why or why not?\nYes, I would definitely recommend it. The supportive environment, relevant tasks, excellent mentorship, and positive culture make it an outstanding opportunity to learn and grow professionally.\nSuggestions \u0026amp; Expectations Would you like to continue this program in the future?\nAbsolutely ‚Äî I would be very interested in returning for another internship or even a full-time role after graduation.\nAny other comments (free sharing):\nThank you to the entire FCJ team for such a welcoming and enriching experience. I‚Äôve learned a lot, feel much more confident in my abilities, and truly enjoyed my time here!\n"},{"uri":"https://thormastran.github.io/fcj-workshop-template/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://thormastran.github.io/fcj-workshop-template/tags/","title":"Tags","tags":[],"description":"","content":""}]